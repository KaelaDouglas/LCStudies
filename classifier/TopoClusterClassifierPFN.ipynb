{
 "metadata": {
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import uproot as ur\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "\n",
    "mac = False\n",
    "\n",
    "data_path = '/fast_scratch/atlas_images/v01-45/'\n",
    "if mac:\n",
    "    data_path = '/Users/swiatlow/Data/caloml/graph_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"7\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# energyflow imports\n",
    "import energyflow as ef\n",
    "from energyflow.archs import PFN\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(data_path+'X.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.keras.utils.to_categorical(np.concatenate((np.ones(90000), np.zeros(90000))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_sizes, F_sizes = (50, 50, 64), (50, 50, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done train/val/test split\n"
     ]
    }
   ],
   "source": [
    "from energyflow.utils import data_split\n",
    "\n",
    "# do train/val/test split \n",
    "(X_train, X_val, X_test,\n",
    " Y_train, Y_val, Y_test) = data_split(X, Y, val=10000, test=40000)\n",
    "\n",
    "print('Done train/val/test split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput (InputLayer)              [(None, None, 3)]    0                                            \n__________________________________________________________________________________________________\ntdist_0 (TimeDistributed)       (None, None, 50)     200         input[0][0]                      \n__________________________________________________________________________________________________\nactivation (Activation)         (None, None, 50)     0           tdist_0[0][0]                    \n__________________________________________________________________________________________________\ntdist_1 (TimeDistributed)       (None, None, 50)     2550        activation[0][0]                 \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, None, 50)     0           tdist_1[0][0]                    \n__________________________________________________________________________________________________\ntdist_2 (TimeDistributed)       (None, None, 64)     3264        activation_1[0][0]               \n__________________________________________________________________________________________________\nmask (Lambda)                   (None, None)         0           input[0][0]                      \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, None, 64)     0           tdist_2[0][0]                    \n__________________________________________________________________________________________________\nsum (Dot)                       (None, 64)           0           mask[0][0]                       \n                                                                 activation_2[0][0]               \n__________________________________________________________________________________________________\ndense_0 (Dense)                 (None, 50)           3250        sum[0][0]                        \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 50)           0           dense_0[0][0]                    \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 50)           2550        activation_3[0][0]               \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 50)           0           dense_1[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 50)           2550        activation_4[0][0]               \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 50)           0           dense_2[0][0]                    \n__________________________________________________________________________________________________\noutput (Dense)                  (None, 2)            102         activation_5[0][0]               \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 2)            0           output[0][0]                     \n==================================================================================================\nTotal params: 14,466\nTrainable params: 14,466\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "260/260 [==============================] - 10s 30ms/step - loss: 6.3019 - acc: 0.5695 - val_loss: 0.5772 - val_acc: 0.7296\n",
      "Epoch 2/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.7875 - acc: 0.7328 - val_loss: 0.6091 - val_acc: 0.7945\n",
      "Epoch 3/50\n",
      "260/260 [==============================] - 8s 32ms/step - loss: 0.6436 - acc: 0.7598 - val_loss: 0.7578 - val_acc: 0.6664\n",
      "Epoch 4/50\n",
      "260/260 [==============================] - 7s 29ms/step - loss: 0.7102 - acc: 0.7359 - val_loss: 0.4961 - val_acc: 0.8017\n",
      "Epoch 5/50\n",
      "260/260 [==============================] - 7s 29ms/step - loss: 0.6080 - acc: 0.7564 - val_loss: 0.5906 - val_acc: 0.7820\n",
      "Epoch 6/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.5482 - acc: 0.7590 - val_loss: 0.5911 - val_acc: 0.7798\n",
      "Epoch 7/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.5074 - acc: 0.7713 - val_loss: 0.4437 - val_acc: 0.7953\n",
      "Epoch 8/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.6076 - acc: 0.7512 - val_loss: 0.4812 - val_acc: 0.7405\n",
      "Epoch 9/50\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.4766 - acc: 0.7780 - val_loss: 0.4551 - val_acc: 0.7727\n",
      "Epoch 10/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.4994 - acc: 0.7715 - val_loss: 0.4623 - val_acc: 0.8027\n",
      "Epoch 11/50\n",
      "260/260 [==============================] - 7s 29ms/step - loss: 0.4499 - acc: 0.7924 - val_loss: 0.4759 - val_acc: 0.7382\n",
      "Epoch 12/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.4586 - acc: 0.7895 - val_loss: 0.4303 - val_acc: 0.8092\n",
      "Epoch 13/50\n",
      "260/260 [==============================] - 7s 29ms/step - loss: 0.4569 - acc: 0.7917 - val_loss: 0.4344 - val_acc: 0.7928\n",
      "Epoch 14/50\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.4546 - acc: 0.7938 - val_loss: 0.4222 - val_acc: 0.8074\n",
      "Epoch 15/50\n",
      "260/260 [==============================] - 8s 29ms/step - loss: 0.4870 - acc: 0.7846 - val_loss: 0.3962 - val_acc: 0.8168\n",
      "Epoch 16/50\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.4262 - acc: 0.8143 - val_loss: 0.3882 - val_acc: 0.8293\n",
      "Epoch 17/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.4220 - acc: 0.8076 - val_loss: 0.6207 - val_acc: 0.7685\n",
      "Epoch 18/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.4617 - acc: 0.7884 - val_loss: 0.4070 - val_acc: 0.8128\n",
      "Epoch 19/50\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.4135 - acc: 0.8090 - val_loss: 0.4017 - val_acc: 0.8145\n",
      "Epoch 20/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.3898 - acc: 0.8241 - val_loss: 0.3871 - val_acc: 0.8479\n",
      "Epoch 21/50\n",
      "260/260 [==============================] - 7s 26ms/step - loss: 0.3921 - acc: 0.8291 - val_loss: 0.4067 - val_acc: 0.8261\n",
      "Epoch 22/50\n",
      "260/260 [==============================] - 7s 26ms/step - loss: 0.3719 - acc: 0.8419 - val_loss: 0.3328 - val_acc: 0.8414\n",
      "Epoch 23/50\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.3423 - acc: 0.8510 - val_loss: 0.3239 - val_acc: 0.8561\n",
      "Epoch 24/50\n",
      "260/260 [==============================] - 7s 26ms/step - loss: 0.3157 - acc: 0.8649 - val_loss: 0.3037 - val_acc: 0.8734\n",
      "Epoch 25/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.2933 - acc: 0.8759 - val_loss: 0.2803 - val_acc: 0.8704\n",
      "Epoch 26/50\n",
      "260/260 [==============================] - 7s 26ms/step - loss: 0.2940 - acc: 0.8792 - val_loss: 0.2797 - val_acc: 0.8847\n",
      "Epoch 27/50\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.2834 - acc: 0.8819 - val_loss: 0.2656 - val_acc: 0.8921\n",
      "Epoch 28/50\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.2756 - acc: 0.8867 - val_loss: 0.2773 - val_acc: 0.8910\n",
      "Epoch 29/50\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.2734 - acc: 0.8892 - val_loss: 0.2750 - val_acc: 0.8827\n",
      "Epoch 30/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.2730 - acc: 0.8878 - val_loss: 0.2746 - val_acc: 0.8859\n",
      "Epoch 31/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.2675 - acc: 0.8903 - val_loss: 0.2640 - val_acc: 0.8929\n",
      "Epoch 32/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.2719 - acc: 0.8878 - val_loss: 0.2590 - val_acc: 0.8966\n",
      "Epoch 33/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.2792 - acc: 0.8855 - val_loss: 0.2616 - val_acc: 0.8906\n",
      "Epoch 34/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.2663 - acc: 0.8906 - val_loss: 0.2669 - val_acc: 0.8933\n",
      "Epoch 35/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.2630 - acc: 0.8918 - val_loss: 0.2625 - val_acc: 0.8947\n",
      "Epoch 36/50\n",
      "260/260 [==============================] - 7s 29ms/step - loss: 0.2719 - acc: 0.8890 - val_loss: 0.2592 - val_acc: 0.8996\n",
      "Epoch 37/50\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.2586 - acc: 0.8934 - val_loss: 0.2630 - val_acc: 0.8900\n",
      "Epoch 38/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.2611 - acc: 0.8930 - val_loss: 0.2750 - val_acc: 0.8865\n",
      "Epoch 39/50\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.2661 - acc: 0.8898 - val_loss: 0.2674 - val_acc: 0.8958\n",
      "Epoch 40/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.2598 - acc: 0.8938 - val_loss: 0.2479 - val_acc: 0.8987\n",
      "Epoch 41/50\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.2896 - acc: 0.8879 - val_loss: 0.4525 - val_acc: 0.7484\n",
      "Epoch 42/50\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.4193 - acc: 0.7944 - val_loss: 0.3396 - val_acc: 0.8690\n",
      "Epoch 43/50\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.3320 - acc: 0.8637 - val_loss: 0.3051 - val_acc: 0.8747\n",
      "Epoch 44/50\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.2968 - acc: 0.8759 - val_loss: 0.2845 - val_acc: 0.8795\n",
      "Epoch 45/50\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.2872 - acc: 0.8810 - val_loss: 0.2758 - val_acc: 0.8845\n",
      "Epoch 46/50\n",
      "260/260 [==============================] - 7s 26ms/step - loss: 0.2825 - acc: 0.8843 - val_loss: 0.2665 - val_acc: 0.8921\n",
      "Epoch 47/50\n",
      "260/260 [==============================] - 7s 26ms/step - loss: 0.2710 - acc: 0.8907 - val_loss: 0.2626 - val_acc: 0.8943\n",
      "Epoch 48/50\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.2713 - acc: 0.8901 - val_loss: 0.2608 - val_acc: 0.8949\n",
      "Epoch 49/50\n",
      "260/260 [==============================] - 7s 28ms/step - loss: 0.2649 - acc: 0.8925 - val_loss: 0.2647 - val_acc: 0.8934\n",
      "Epoch 50/50\n",
      "260/260 [==============================] - 7s 26ms/step - loss: 0.2605 - acc: 0.8951 - val_loss: 0.2727 - val_acc: 0.8857\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f39a7f90730>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# train model\n",
    "history = pfn.fit(X_train, Y_train,\n",
    "        epochs=100,\n",
    "        batch_size=500,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pfn.predict(X_test, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nPFN AUC: 0.9548550671434395\n\n"
     ]
    }
   ],
   "source": [
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    plt.cla(); plt.clf()\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_facecolor('white')\n",
    "\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    # plt.savefig('Plots/accuracy_' + layer + '.pdf')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # summarize history for loss\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_facecolor('white')\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    # plt.savefig(plotpath + 'loss_' + layer + '.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}