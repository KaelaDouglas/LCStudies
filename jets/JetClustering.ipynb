{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jet Clustering using \"Smart Topo-Clusters\"\n",
    "\n",
    "The big idea is to use neural networks for classification and/or energy calibration of topo-clusters, and use these topo-clusters for making jets. In this notebook I'll be playing around with some ideas for this, to see what works.\n",
    "\n",
    "In this notebook we will *not* be training neural networks. That's taken care of by other notebooks in the `/classifier` and `/regression` directories of this repo. We will instead be applying the existing, trained networks to some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Setup\n",
    "\n",
    "First, let's import a bunch of packages we know we'll need right off-the-bat.\n",
    "\n",
    "Note that as we've set up our environment with `conda`, our `ROOT` installation has all the bells and whistles. This includes the `pythia8` library and its associated `ROOT` wrapper, `TPythia8`. We can optionally use this for jet-clustering, as it comes `fj-core`.\n",
    "Alternatively we could use the Pythonic interface for `fastjet` or [pyjet](https://github.com/scikit-hep/pyjet), but the latter requires linking an external fastjet build for speed and this doesn't seem to work when following their documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ROOT as rt\n",
    "import uproot as ur\n",
    "#import pandas as pd\n",
    "import sys, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's also some slightly contrived setup for `latex`. We may need this for the `atlas_mpl_style` package, which is employed in some of Max's plotting utilities that we may want to borrow. Since `latex` isn't set up on the [UChicago ML platform](https://ml.maniac.uchicago.edu) by default, our setup script may install it separately but it's still not on `$PATH` since we don't touch our bash profile. This cell uses some `IPython` magic to adjust `$PATH` for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if latex is set up already.\n",
    "# We use some Jupyter magic -- alternatively one could use python's subprocess here.\n",
    "has_latex = !command -v latex\n",
    "has_latex = (not has_latex == [])\n",
    "\n",
    "# If latex was not a recognized command, our setup script should have installed\n",
    "# at a fixed location, but it is not on the $PATH. Now let's use some Jupyter magic.\n",
    "# See https://ipython.readthedocs.io/en/stable/interactive/shell.html for info.\n",
    "if(not has_latex):\n",
    "    latex_prefix = '/usr/local/texlive/2020/bin/x86_64-linux'\n",
    "    jupyter_env = %env\n",
    "    path = jupyter_env['PATH']\n",
    "    path = path + ':' + latex_prefix\n",
    "    %env PATH = $path\n",
    "    jupyter_env = %env\n",
    "    path = jupyter_env['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some extra setup\n",
    "path_prefix = '/workspace/LCStudies/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Fetching the data\n",
    "\n",
    "Now we get our data. For now, our classifiers are being trained to distinguish between $\\pi^+$ and $\\pi^0$. Assuming that all charged pions behave the same way, we can really treat this as a $\\pi^\\pm$ vs. $\\pi^0$ classifier. **For our toy workflow, we'll say that we only want to cluster $\\pi^\\pm$ topo-clusters into jets.** We will treat $\\pi^0$ as a background.\n",
    "\n",
    "For our input data, we have `ROOT` files containing a tree called `ClusterTree`. In each tree, each entry corresponds with one topo-cluster, and the different files correspond with different topo-cluster parent particles (e.g. $3$ files for $\\pi^+$,$\\pi^-$ and $\\pi^0$). Each topo-cluster entry contains information on the event from which it came (\"runNumber\" and \"eventNumber\"), and many topo-clusters (within and across files) share the same event. Our ultimate goal is to regroup this data into one file where each entry corresponds with one *event*. This is a sensible way to arrange the data before performing any jet clustering (which is performed by event), and writing to a file will allow us to skip this whole process after doing it once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(path_prefix not in sys.path): sys.path.append(path_prefix)\n",
    "from  util import ml_util as mu\n",
    "\n",
    "# ----- Meta-data for our dataset -----\n",
    "layers = [\"EMB1\", \"EMB2\", \"EMB3\", \"TileBar0\", \"TileBar1\", \"TileBar2\"]\n",
    "nlayers = len(layers)\n",
    "cell_size_phi = [0.098, 0.0245, 0.0245, 0.1, 0.1, 0.1]\n",
    "cell_size_eta = [0.0031, 0.025, 0.05, 0.1, 0.1, 0.2]\n",
    "len_phi = [4, 16, 16, 4, 4, 4]\n",
    "len_eta = [128, 16, 8, 4, 4, 2]\n",
    "assert(len(len_phi) == nlayers)\n",
    "assert(len(len_eta) == nlayers)\n",
    "meta_data = {\n",
    "    layers[i]:{\n",
    "        'cell_size':(cell_size_eta[i],cell_size_phi[i]),\n",
    "        'dimensions':(len_eta[i],len_phi[i])\n",
    "    }\n",
    "    for i in range(nlayers)\n",
    "}\n",
    "# -------------------------------------\n",
    "\n",
    "# We open the files using uproot, and use our ml_util to get the images.\n",
    "data_dir = '/workspace/LCStudies/data'\n",
    "data_files = glob.glob(data_dir + '/*.root')\n",
    "data_files = {x.split('/')[-1].replace('.root',''):x for x in data_files}\n",
    "tree_name = 'ClusterTree'\n",
    "trees = {key: ur.open(file)[tree_name] for key, file in data_files.items()}\n",
    "\n",
    "pcells = {\n",
    "    ifile : {\n",
    "        layer : mu.setupCells(itree, layer)\n",
    "        for layer in layers\n",
    "    }\n",
    "    for ifile, itree in trees.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Applying the classifier network\n",
    "\n",
    "Our first step is to get the network scores for each topo-cluster. We will place these in \"friend trees\" of our input trees. (To be more precise, we will chain together the input trees, and the trees we make here, and then make these $2$ `TChain`s friends).\n",
    "\n",
    "To do this, let's import some `tensorflow` and `keras` stuff that we'll need for applying our trained networks to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # disable some of the tensorflow info printouts, only display errors\n",
    "ngpu = 1\n",
    "gpu_list = [\"/gpu:\"+str(i) for i in range(ngpu)]\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=gpu_list)\n",
    "ngpu = strategy.num_replicas_in_sync\n",
    "print ('Number of devices: {}'.format(ngpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from  util import qol_util as qu\n",
    "modelpath = path_prefix + 'classifier/Models'\n",
    "model_postfix = '_flat_do20' # for our simple, per-layer NN's\n",
    "models = {}\n",
    "model_history = {}\n",
    "model_scores = {}\n",
    "\n",
    "i = 0\n",
    "for layer in layers:\n",
    "    if(i == 0): print('Loading ',end='')\n",
    "    print(layer,end='')\n",
    "    if(i!= len(layers)-1): print(', ',end='')\n",
    "    else: print('.')\n",
    "    i += 1\n",
    "    \n",
    "    models[layer] = tf.keras.models.load_model(modelpath+'/model_' + layer + model_postfix + '.h5')\n",
    "    # Load history object.\n",
    "    with open(modelpath + '/model_' + layer + model_postfix + '.history','rb') as model_history_file:\n",
    "        model_history[layer] = pickle.load(model_history_file)\n",
    "    \n",
    "# Recalculate network scores for the datasets.\n",
    "prefix = 'Calculating network scores:'\n",
    "l = len(pcells) * len(layers)\n",
    "qu.printProgressBar(0, l, prefix=prefix, suffix='Complete', length=50)\n",
    "i = 0\n",
    "for key in pcells.keys():\n",
    "    \n",
    "    model_scores[key] = {}\n",
    "    for layer in layers: \n",
    "        model_scores[key][layer] = models[layer].predict(pcells[key][layer])\n",
    "        i += 1\n",
    "        qu.printProgressBarColor(i, l, prefix=prefix, suffix='Complete', length=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each event, the corresponding `model_scores` entry is a tuple.\n",
    "The first entry is the \"background score\" -- how likely the cluster is to be a $\\pi^0$. The second is the \"signal score\" -- how likely the cluster is to be a $\\pi^\\pm$. At least this seems to be the correct interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our network scores for all our clusters, we need to group our clusters by event -- in a new file. As each entry will correspond with one event, most of our scalar branches will now become arrays, listing properties for each cluster in the event. We could try to be fancy and make these branches of C++-type `std::vector` instead, but as some are multi-dim arrays we would end up with vectors of C++-style arrays and handling these via the `PyROOT` interface seems problematic/tough to me.\n",
    "\n",
    "\n",
    "Note that besides the signal flag and network scores, we're also adding a \"file index\". This is a simple constant branch that keeps the entries from different files distinct. It could, in principle, let us distinguish underlying truth particle flavors beyond just \"signal\" and \"background\" (e.g. distinguish between $\\pi^+$ and $\\pi^-$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_definition = {'signal':['piminus','piplus'],'background':['pi0']}\n",
    "\n",
    "from  util import qol_util as qu\n",
    "from pathlib import Path\n",
    "jet_data_dir = path_prefix + 'jets/data'\n",
    "Path(jet_data_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Get our original data files.\n",
    "files = {key:rt.TFile(file,'READ') for key, file in data_files.items()}\n",
    "trees = {key:file.Get(tree_name) for key, file in files.items()}\n",
    "\n",
    "# Now we want to effectively add some new columns. We accomplish this with \"friend\" trees.\n",
    "# We're not actually making these trees friends yet. Instead we will form TChains and friend those.\n",
    "\n",
    "# Creating our branch buffer.\n",
    "data = {\n",
    "    'signal':np.zeros(1,dtype=np.dtype('i2')),\n",
    "    'file_index'   :np.zeros(1,dtype=np.dtype('i2')) # TODO: Is this needed any longer?\n",
    "}\n",
    "for layer in layers:\n",
    "    bname = layer + '_NN'\n",
    "    data[bname] = np.zeros(2,dtype=np.dtype('f8'))\n",
    "\n",
    "friend_tree_name = tree_name + '_friend'\n",
    "friend_data_files = {}\n",
    "\n",
    "file_index = 0\n",
    "\n",
    "for key in sorted(trees.keys()):\n",
    "    \n",
    "    friend_filename = data_files[key].split('/')[-1]\n",
    "    friend_filename = jet_data_dir + '/' + friend_filename\n",
    "    friend_file = rt.TFile(friend_filename,'RECREATE')\n",
    "    friend_data_files[key] = friend_filename\n",
    "    \n",
    "    friend_tree = rt.TTree(friend_tree_name,friend_tree_name)\n",
    "    branches = {}\n",
    "\n",
    "    # --- Setup the branches using our buffer. This is a rather general/flexible code block. ---\n",
    "    for bname, val in data.items():\n",
    "        descriptor = bname\n",
    "        bshape = val.shape\n",
    "        if(bshape != (1,)):\n",
    "            for i in range(len(bshape)):\n",
    "                descriptor += '[' + str(bshape[i]) + ']'\n",
    "        descriptor += '/'\n",
    "        if(val.dtype == np.dtype('i2')): descriptor += 'S'\n",
    "        elif(val.dtype == np.dtype('i4')): descriptor += 'I'\n",
    "        elif(val.dtype == np.dtype('i8')): descriptor += 'L'\n",
    "        elif(val.dtype == np.dtype('f4')): descriptor += 'F'\n",
    "        elif(val.dtype == np.dtype('f8')): descriptor += 'D'\n",
    "        else:\n",
    "            print('Warning, setup issue for branch: ', key, '. Skipping.')\n",
    "            continue\n",
    "        branches[key] = friend_tree.Branch(bname,val,descriptor)\n",
    "    # --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---\n",
    "    \n",
    "    # Now we fill the friend tree.\n",
    "    nentries = trees[key].GetEntries()\n",
    "    for layer in layers: assert len(model_scores[key][layer]) == nentries\n",
    "\n",
    "    # Signal flag and file index will be constant since input trees are divided by particle identity.\n",
    "    sig = 0\n",
    "    if(key in sig_definition['signal']): sig = 1\n",
    "    nn_scores = model_scores[key]\n",
    "    \n",
    "    prefix = 'Filling friend tree for ' + key + ':'\n",
    "    if(len(prefix) < 32): prefix = prefix + ' ' * (32 - len(prefix))\n",
    "    qu.printProgressBar(0, int(nentries/100), prefix=prefix, suffix='Complete', length=50)\n",
    "    \n",
    "    for i in range(nentries):\n",
    "        data['signal'][0] = sig\n",
    "        for layer in layers: data[layer + '_NN'][:] = nn_scores[layer][i,:]\n",
    "        friend_tree.Fill()\n",
    "        if(i%100 ==0): qu.printProgressBarColor(i/100, int(nentries/100), prefix=prefix, suffix='Complete', length=50)\n",
    "    \n",
    "    friend_tree.Write()\n",
    "    friend_file.Close()\n",
    "    file_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our trees containing the signal flag and network scores are now saved to disk. Now let's make `TChain`s and make them friends, so that we've effectively tacked on new columns to our original data. We will then save these `TChain`s as a `TTree` to an uncompressed file, and use the `TTreeIndex` functionality to sort our events. We do this conversion & saving because it appears to greatly speed up our reading when using the `TTreeIndex`. I assume this has to do something with the entries -- from both the main chain and its friend -- all being saved in the same file as opposed to being scattered across multiple ones. ([See here](https://root-forum.cern.ch/t/usage-of-tchainindex/19074/4) for a discussion of `TChainIndex` versus `TTreeIndex`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = rt.TChain(tree_name)\n",
    "friend_chain = rt.TChain(friend_tree_name)\n",
    "for key in data_files.keys(): \n",
    "    chain.AddFile(data_files[key],-1)\n",
    "    friend_chain.AddFile(friend_data_files[key],-1)\n",
    "    \n",
    "chain_filename = jet_data_dir + '/' + 'clusters.root'\n",
    "chain_file = rt.TFile(chain_filename,'RECREATE','',0) # uncompressed file\n",
    "clone = chain.CloneTree(-1,'FAST')\n",
    "friend_clone = friend_chain.CloneTree(-1,'FAST')\n",
    "clone.Write()\n",
    "friend_clone.Write()\n",
    "chain_file.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_file = rt.TFile(chain_filename,'READ')\n",
    "chain = chain_file.Get(tree_name)\n",
    "friend_chain = chain_file.Get(friend_tree_name)\n",
    "assert(chain.GetEntries() == friend_chain.GetEntries()) # number of entries must match, otherwise something has gone very wrong\n",
    "nentries = chain.GetEntries()\n",
    "chain.AddFriend(friend_chain)\n",
    "print('The chains are now friends.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, one of the branches of the input data is of type `std::vector<Float_t>`, while all the others are either scalars or fixed-length arrays (sometimes with an effective variable length encoded in another branch). Let's see what the length of this vector branch looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating the cluster_cellE_norm branch, which is the only vector branch (variable-length). Why?\n",
    "histo = rt.TH1I('h0','len(cluster_cellE_norm)',250,0,1000)\n",
    "nentries = chain.GetEntriesFast()\n",
    "stride = 200\n",
    "qu.printProgressBar(0, int(nentries/stride), prefix='Drawing:', suffix='Complete', length=50)\n",
    "for i in range(nentries):\n",
    "    chain.GetEntry(i)\n",
    "    histo.Fill(len(chain.cluster_cellE_norm))\n",
    "    if(i%stride == 0): qu.printProgressBarColor(i/stride, int(nentries/stride), prefix='Drawing:', suffix='Complete', length=50)\n",
    "\n",
    "canv = rt.TCanvas('c1,','c1',800,600)\n",
    "histo.Draw('HIST')\n",
    "canv.SetLogy()\n",
    "histo.SetMinimum(0.1)\n",
    "canv.Draw()\n",
    "\n",
    "max_length = int(histo.GetXaxis().GetBinCenter(histo.FindLastBinAbove(0)))\n",
    "print('Max length is ' + str(max_length) + '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a function to quickly get the maximum length of a vector branch in our tree. We only have one vector branch for now but there may be others with a future dataset.\n",
    "\n",
    "This will let us turn the branch from one of type vector to one of type array. It's useful if we're adding an extra dimension, as I'm currently having issues with making branches like vectors of arrays on the Python side of things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMaxVectorLength(chain, branchname):\n",
    "    draw_string = branchname + '@.size()'\n",
    "    chain.Draw(draw_string)\n",
    "    h = rt.gPad.GetPrimitive('htemp') # some slightly idiomatic ROOT stuff, one of the few examples of weird default behavior\n",
    "    max_length = int(h.GetXaxis().GetBinCenter(h.FindLastBinAbove(0)))\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create our `TTreeIndex`. We will use the branch `eventNumber` as our `majornumber`, so that the index effectively sorts our tree by `eventNumber` and we have our events grouped together. Since there are many duplicate `eventNumber` entries, and we do not use any `minornumber`, this is *not* a unique index. But this is fine, because we do not care about the sorting within any single `eventNumber` value. It just means that we *cannot* access every single entry with a call to `TTreeIndex::GetEntryNumberWithIndex()`, but rather we'll have to loop through the elements of `TTreeIndex:GetIndex()` sequentially.\n",
    "\n",
    "**TODO:** As a consequence of our indexing, we do not protect against the possibility of two clusters having the same `eventNumber` but different `runNumber`s. We should add this at some point to avoid the possibility of mixing clusters from what are really separate events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting minornumber to 0 effectively gets rid of it\n",
    "chain_idx = rt.TTreeIndex(chain,'eventNumber','0') # TODO: consider changing to majornumber=runNumber, minorNumber=eventNumber. In this particular case runNumber is always the same.\n",
    "n_idx = chain_idx.GetN()\n",
    "assert(n_idx == chain.GetEntriesFast()) # ensure our TTreeIndex is of the right length, otherwise something is wrong\n",
    "chain_indices = chain_idx.GetIndex() # a C++-style array of (ROOT) type Long64_t...\n",
    "chain_indices = np.array([chain_indices[i] for i in range(n_idx)],dtype=np.dtype('i8')) #... now a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to copy our data to a new `ROOT` file, where each entry corresponds with an **event**. Our `chain_indices` lets us loop through the existing data in a sensible way.\n",
    "\n",
    "Certain variables are *per-event* variables, such as `runNumber`. These will remain as scalars. Other variables are *per-cluster* variables, such as `clusterE` (scalar) or `EMB1` (2D vector). These will become *arrays* of whatever their previous type was. The branch `nCluster` will keep track of their length for each event. Note that this means we be rewriting the contents of the `nCluster` branch, rather than copying it over -- it currently only keeps track of the number of clusters per event per file, not the total number of clusters per event.\n",
    "\n",
    "As one last note, we will have to be a little careful about looping through our `TChain` of input trees for the sake of speed. We're using a `TTreeIndex` that we built, but this will amount to hopping around a lot (reading entries in a very non-sequential order w.r.t. the chain/trees). [This can slow things down with a lot of file I/0](https://root-forum.cern.ch/t/ttree-getentry-with-a-ttreeindex-is-too-slow/17370/5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting from ROOT type names to leaflist decorators.\n",
    "# Vector decorator will not work, but gives a sensible string\n",
    "# telling us the depth (how many vectors).\n",
    "def RTypeConversion(type_string):\n",
    "    if(type_string == 'Short_t' or type_string == 'short'):    return 'S'\n",
    "    elif(type_string == 'Int_t' or type_string == 'int'):    return 'I'\n",
    "    elif(type_string == 'Float_t' or type_string == 'float'):  return 'F'\n",
    "    elif(type_string == 'Double_t' or type_string == 'double'): return 'D'\n",
    "    elif('vector' in type_string): # special case\n",
    "#         type_substring = '<'.join(type_string.split('<')[1:])\n",
    "#         type_substring = '>'.join(type_substring.split('>')[:-1])\n",
    "#         type_substring = RTypeConversion(type_substring)\n",
    "#         return 'v_' + type_substring\n",
    "        return type_string\n",
    "    else: return '?'\n",
    "\n",
    "def GetShape(shape_string):\n",
    "    dims = shape_string.replace('[',' ').replace(']', ' ').split()\n",
    "    return tuple([int(x) for x in dims])\n",
    "\n",
    "def RType2NType(type_string):\n",
    "    if(type_string == 'S'):   return np.dtype('i2')\n",
    "    elif(type_string == 'I'): return np.dtype('i4')\n",
    "    elif(type_string == 'L'): return np.dtype('i8')\n",
    "    elif(type_string == 'F'): return np.dtype('f4')\n",
    "    elif(type_string == 'D'): return np.dtype('f8')\n",
    "    else: raise ValueError('Input not understood.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find a better way of dealing with variable number of clusters per event (e.g. ROOT vectors).\n",
    "# Currently limited because branches like EMB1 are multi-dim arrays, and I cannot make std::vector's of arrays.\n",
    "n_clusters_max = int(len(data_files.keys()) * chain.GetMaximum('nCluster')) # safe upper limit, but might be unnecessarily high\n",
    "\n",
    "# Building our branch buffer for our new trees. This time we'll add leaflists to the buffer as well.\n",
    "# Slightly hacky but this should be pretty flexible for any basic-type branches.\n",
    "\n",
    "branch_info = [x.GetListOfLeaves()[0] for x in chain.GetListOfBranches()]\n",
    "branch_info = [(x.GetTitle(),x.GetTypeName()) for x in branch_info]\n",
    "branch_names = [x[0].split('[')[0] for x in branch_info]\n",
    "\n",
    "friend_branch_info = [x.GetListOfLeaves()[0] for x in friend_chain.GetListOfBranches()]\n",
    "friend_branch_info = [(x.GetTitle(),x.GetTypeName()) for x in friend_branch_info]\n",
    "friend_branch_names = [x[0].split('[')[0] for x in friend_branch_info]\n",
    "\n",
    "branch_names = branch_names + friend_branch_names\n",
    "\n",
    "# Now let's consider removing some branches that we don't think we'll need for our event dataset.\n",
    "# This can potentially speed things up a lot. Especially true for branches of type std::vector at the moment,\n",
    "# as I am probably not handling them in the smartest way.\n",
    "branch_names_remove = ['cluster_cellE_norm']\n",
    "\n",
    "perEvent = ['runNumber','eventNumber','nCluster','file_index'] # keep track of which branches only need one entry per event\n",
    "vector_branches = [] # keep track of any branches that are of (C++) type std::vector\n",
    "\n",
    "# We must also keep track of the original shapes of any array branches that we read, as they will be read out as 1D cppy arrays\n",
    "# and will need to be reshaped before being placed in our buffer.\n",
    "input_shapes = {}\n",
    "\n",
    "branch_buffer = {}\n",
    "for entry in branch_info: \n",
    "    name = entry[0]\n",
    "    rtype = RTypeConversion(entry[1])\n",
    "    shape = (1,)\n",
    "    shape_string = ''\n",
    "    if('[' in name): \n",
    "        shape_string = '[' + '['.join(name.split('[')[1:])\n",
    "        shape = GetShape(shape_string)\n",
    "    name = name.split('[')[0]\n",
    "    if(name in branch_names_remove): continue\n",
    "    \n",
    "    # save the original shapes of non-scalar branches\n",
    "    if(shape != (1,)): input_shapes[name] = shape # save the original shape\n",
    "\n",
    "    if(name not in perEvent):\n",
    "        if(shape == (1,)): \n",
    "            shape = (n_clusters_max,)\n",
    "            shape_string = '[' + 'nCluster' + ']'\n",
    "        else:\n",
    "            shape2 = [n_clusters_max]\n",
    "            for x in shape: shape2.append(x)\n",
    "            shape = tuple(shape2)\n",
    "            shape_string = '[' + 'nCluster' + ']' + shape_string\n",
    "      \n",
    "    if('vector' in rtype):\n",
    "        continue\n",
    "        # We will make the vector into an array. Assuming vector is of some basic type! (not vector of vectors, etc.)\n",
    "        rsubtype = '<'.join(rtype.split('<')[1:])\n",
    "        rsubtype = '>'.join(rsubtype.split('>')[:-1])\n",
    "        rtype = RTypeConversion(rsubtype)\n",
    "        n_max = GetMaxVectorLength(chain,name)\n",
    "        input_shapes[name]=(n_max,)\n",
    "        shape = tuple(list(shape) + [n_max])\n",
    "        shape_string += '[' + str(n_max) + ']'\n",
    "        vector_branches.append(name)\n",
    "        #branch_buffer[name] = [rt.vector(rsubtype)(),0]\n",
    "        #TODO: Add a branch for the vector length\n",
    "        \n",
    "    branch_buffer[name] = [np.zeros(shape,dtype=RType2NType(rtype)),name + shape_string + '/' + rtype]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining how many events to write. By default we want them all, but for debugging we might only want some subset.\n",
    "nevents = -1\n",
    "nentries = chain_indices.shape[0]\n",
    "if(nevents > 0):\n",
    "    # determine how many entries we need to get this many events\n",
    "    chain.SetBranchStatus('*',0)\n",
    "    chain.SetBranchStatus('eventNumber',1)\n",
    "    nevents_tally = 0\n",
    "    chain.GetEntry(chain_indices[0])\n",
    "    eN_prev = chain.eventNumber\n",
    "    for i in range(nentries):\n",
    "        chain.GetEntry(chain_indices[i])\n",
    "        if(chain.eventNumber != eN_prev): nevents_tally += 1\n",
    "        eN_prev = chain.eventNumber\n",
    "        if(nevents_tally == nevents):\n",
    "            nentries = i-1 # don't include the event we've just started\n",
    "            break\n",
    "  \n",
    "if(nevents <= 0): nevents = 'all'\n",
    "report_string = 'Preparing to write {nev} events, corresponding to {nen} input topo-clusters.'.format(nev=nevents,nen=nentries)\n",
    "print(report_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate the branches we need, keep any ignored ones deactivated\n",
    "chain.SetBranchStatus('*',1)\n",
    "for name in branch_names_remove: chain.SetBranchStatus(name,0)\n",
    "    \n",
    "# Strategies for speeding things up more. \n",
    "strategy = 1\n",
    "\n",
    "if(strategy == 1):\n",
    "    filesize = chain_file.GetSize() # in bytes\n",
    "    chain.SetMaxVirtualSize(2 * filesize)\n",
    "    for name in branch_names:\n",
    "        if(name not in branch_names_remove): chain.GetBranch(name).LoadBaskets()\n",
    "    print('Employing strategy 1 (load full input tree into memory).')\n",
    "\n",
    "elif(strategy == 2):\n",
    "    # Increasing basket_size will help a little. But because entry access is somewhat random,\n",
    "    # performance will quickly plateau and big increases may not give any real gains.\n",
    "    basket_size_multiplier = 3\n",
    "    basket_size = 16000 * basket_size_multiplier\n",
    "    for name in branch_names:\n",
    "        if(name in branch_names_remove): continue\n",
    "        if(name in friend_branch_names): friend_chain.SetBasketSize(name,basket_size)\n",
    "        else: chain.SetBasketSize(name,basket_size)\n",
    "    print('Employing strategy 2 (increasing basket size for input tree).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "Path(jet_data_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Make the new TFile and TTree.\n",
    "event_filename = path_prefix + 'jets/data' + '/' + 'events.root'\n",
    "event_treename = 'events'\n",
    "event_file = rt.TFile(event_filename,'RECREATE')\n",
    "event_tree = rt.TTree(event_treename,event_treename)\n",
    "event_tree.SetDirectory(0) # tree will start in memory!\n",
    "\n",
    "# Set up the branches. Note that we must add branches specifying lengths *before*\n",
    "# any branches whose lengths they specify. For now, that means nCluster must go first.\n",
    "# TODO: Make this less hacky.\n",
    "name = 'nCluster'\n",
    "assert(name in branch_buffer.keys())\n",
    "buffer   = branch_buffer[name][0]\n",
    "leaflist = branch_buffer[name][1]\n",
    "event_tree.Branch(name,buffer,leaflist)\n",
    "\n",
    "for key, value in branch_buffer.items():\n",
    "    if(key == 'nCluster'): continue\n",
    "    name = key\n",
    "    buffer = value[0]\n",
    "    leaflist = value[-1]\n",
    "    if(leaflist == 0): event_tree.Branch(name,value[0])\n",
    "    else: event_tree.Branch(name,buffer,leaflist)\n",
    "\n",
    "chain.GetEntry(chain_indices[0])\n",
    "eN_prev = chain.eventNumber\n",
    "cluster_idx = 0\n",
    "\n",
    "stride = int(nentries/100)\n",
    "l = int(nentries/stride)\n",
    "bar_length = 120\n",
    "prefix = 'Writing event tree:'\n",
    "qu.printProgressBar(0, l, prefix=prefix, suffix='Complete', length=bar_length)\n",
    "\n",
    "start = time.time()\n",
    "# dt = np.zeros(5)\n",
    "# Now loop through the input chain and write to our new tree.\n",
    "for i in range(nentries):\n",
    "\n",
    "#     t0 = time.time()\n",
    "    chain.GetEntry(chain_indices[i])\n",
    "    eN = chain.eventNumber\n",
    "#     dt[0] += time.time() - t0\n",
    "    \n",
    "    if(eN != eN_prev):\n",
    "        # We've finished an event and have just entered a new one.\n",
    "        # Write everything that's in the buffer. Corresponds to the previous event.\n",
    "#         t0 = time.time()\n",
    "        event_tree.Fill()\n",
    "        cluster_idx = 0 # reset cluster_idx\n",
    "#         dt[1] += time.time() - t0\n",
    "    \n",
    "    # Fill info from the current event.\n",
    "    for name in branch_buffer.keys():\n",
    "        shape = branch_buffer[name][0].shape\n",
    "        \n",
    "        # Our per-event branches\n",
    "        if(shape == (1,)):\n",
    "#             t0 = time.time()\n",
    "            if(name == 'nCluster'): branch_buffer[name][0][0] = cluster_idx + 1 # will reach max value before write\n",
    "            else: branch_buffer[name][0][0] = getattr(chain,name) # a more C-like way of getting branches\n",
    "#             dt[2] += time.time() - t0\n",
    "        # Our per-cluster branches\n",
    "        else:\n",
    "            ndim = branch_buffer[name][0].ndim\n",
    "            if(ndim == 1): \n",
    "#                 t0 = time.time()\n",
    "                branch_buffer[name][0][cluster_idx] = getattr(chain,name) # per-cluster scalar\n",
    "#                 dt[3] += time.time() - t0\n",
    "            else:\n",
    "                # Multi-dim branches.\n",
    "                # Wrapping with a numpy array works, \n",
    "                # but we must perform the right reshaping.\n",
    "                # std::vector-type branches have variable length - must be careful with reshaping.\n",
    "#                 t0 = time.time()\n",
    "#                 if(name in vector_branches): # Our one vector branch seems to be a culprit for slowdowns.\n",
    "#                     n = len(getattr(chain,name))\n",
    "#                     branch_buffer[name][0][cluster_idx,:n] = np.array(getattr(chain,name))[:]\n",
    "#                     continue\n",
    "                branch_buffer[name][0][cluster_idx,:] = np.array(getattr(chain,name)).reshape(input_shapes[name])[:] # per-cluster array\n",
    "#                 dt[4] += time.time() - t0\n",
    "    \n",
    "    cluster_idx += 1\n",
    "    eN_prev = eN\n",
    "    if(i%stride == 0): qu.printProgressBarColor(int(i/stride), l, prefix=prefix, suffix='Complete', length=bar_length)\n",
    "    # Make sure to call a Fill() if we're at the end of the chain -- we won't be reaching a next event!\n",
    "    if(i == nentries-1): \n",
    "        event_tree.Fill()\n",
    "        #qu.printProgressBar(l, l, prefix=prefix, suffix='Complete', length=bar_length)\n",
    "    \n",
    "event_file.cd()\n",
    "event_tree.Write()\n",
    "# event_file.Write(event_treename,rt.TObject.kOverwrite)\n",
    "event_file.Close()\n",
    "\n",
    "end = time.time()\n",
    "dt_tot = end - start\n",
    "rate = (nentries / dt_tot)\n",
    "print('{val:.1f} seconds. (input data rate = {rate:.1f} Hz)'.format(val=dt_tot,rate=rate))\n",
    "\n",
    "# dt_names = ['GetEntry         ',\n",
    "#             'Write            ',\n",
    "#             'perEvent scalar  ',\n",
    "#             'perCluster scalar',\n",
    "#             'perCluster vector']\n",
    "\n",
    "# for i in range(len(dt)):\n",
    "#     print(dt_names[i] + ': {val:.1f}'.format(val=dt[i]) + ' ({val:.1f})%'.format(val=100. * dt[i] / dt_tot))\n",
    "\n",
    "# diff = dt_tot - np.sum(dt)\n",
    "# print('{val:.1f}'.format(val=100. * diff / dt_tot) + '% of time unaccounted for.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above method is still a little slow -- from a few runs I estimate it takes about $12$ - $15$ minutes to write our `events.root` file, with most of the slowdown having to do with reading entries from `cluster.root` in a non-sequential fashion (this would be much slower had we not exported the contents of our `TChain` to that file). Using our \"strategy \\#1\" from the previous cell really speeds things up, as does turning off the vector branch that we're not using.\n",
    "\n",
    "Note that our current problem does not translate well to multi-threading or parallelization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code below here is unused/testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspace/LCStudies/setup/fastjet/fastjet-install/lib/python3.8/site-packages')\n",
    "import fastjet as fj\n",
    "print(fj.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Little RDataFrame demo.\n",
    "\n",
    "a = range(10)\n",
    "b = np.random.rand(10)\n",
    "df = ROOT.RDataFrame(10)\n",
    "df = df.Define(\"x\", 'auto to_eval = std::string(\"a[\") + std::to_string(rdfentry_) + \"]\"; return float(TPython::Eval(to_eval.c_str()));')\n",
    "df = df.Define(\"y\", 'auto to_eval = std::string(\"b[\") + std::to_string(rdfentry_) + \"]\"; return float(TPython::Eval(to_eval.c_str()));')\n",
    "display = df.Display()\n",
    "display.Print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check showing that clusterIndex is not unique between files.\n",
    "trees = {key:file.Get(tree_name) for key, file in files.items()}\n",
    "t1 = trees['piminus']\n",
    "t2 = trees['piplus']\n",
    "\n",
    "t1_range = range(3,6)\n",
    "t2_range = range(316,318)\n",
    "\n",
    "for i in t1_range:\n",
    "    t1.GetEntry(i)\n",
    "    print(t1.eventNumber,'\\t',t1.clusterIndex)\n",
    "\n",
    "print('---')\n",
    "for i in t2_range:\n",
    "    t2.GetEntry(i)\n",
    "    print(t2.eventNumber,'\\t',t2.clusterIndex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml4p]",
   "language": "python",
   "name": "conda-env-ml4p-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
