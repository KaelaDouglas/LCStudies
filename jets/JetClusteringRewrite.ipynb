{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jet Clustering using \"Smart Topo-Clusters\" \\[Rewrite\\]\n",
    "\n",
    "## Instead of stitching columns with network scores and *then* making an eventTree, we're going to first make an eventTree and *then* stitch on columns with network scores.\n",
    "\n",
    "I have also migrated the event reconstruction (`clusterTree` -> `eventTree`) to a separate workflow, because we will only need to run that once per sample.\n",
    "\n",
    "\n",
    "In this notebook we will *not* be training neural networks. That's taken care of by other notebooks in the `/classifier` and `/regression` directories of this repo. We will instead be applying the existing, trained networks to some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Setup\n",
    "\n",
    "First, let's import a bunch of packages we know we'll need right off-the-bat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/02\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ROOT as rt\n",
    "import uproot as ur\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's also some slightly contrived setup for `latex`. We may need this for the `atlas_mpl_style` package, which is employed in some of Max's plotting utilities that we may want to borrow. Since `latex` isn't set up on the [UChicago ML platform](https://ml.maniac.uchicago.edu) by default, our setup script may install it separately but it's still not on `$PATH` since we don't touch our bash profile. This cell uses some `IPython` magic to adjust `$PATH` for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/opt/conda/envs/ml4p/bin:/opt/conda/condabin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/texlive/2020/bin/x86_64-linux\n"
     ]
    }
   ],
   "source": [
    "# Check if latex is set up already.\n",
    "# We use some Jupyter magic -- alternatively one could use python's subprocess here.\n",
    "has_latex = !command -v latex\n",
    "has_latex = (not has_latex == [])\n",
    "\n",
    "# If latex was not a recognized command, our setup script should have installed\n",
    "# at a fixed location, but it is not on the $PATH. Now let's use some Jupyter magic.\n",
    "# See https://ipython.readthedocs.io/en/stable/interactive/shell.html for info.\n",
    "if(not has_latex):\n",
    "    latex_prefix = '/usr/local/texlive/2020/bin/x86_64-linux'\n",
    "    jupyter_env = %env\n",
    "    path = jupyter_env['PATH']\n",
    "    path = path + ':' + latex_prefix\n",
    "    %env PATH = $path\n",
    "    jupyter_env = %env\n",
    "    path = jupyter_env['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some extra setup\n",
    "path_prefix = '/workspace/LCStudies/'\n",
    "layers = ['EMB1','EMB2','EMB3','TileBar0','TileBar1','TileBar2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Fetching the data\n",
    "\n",
    "In another workflow, [EventReconstruction.ipynb](todo), we built our `eventTree`. Let's get it.\n",
    "\n",
    "For applying network scores, we will be accessing the tree using [uproot](https://uproot.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_data_dir = path_prefix + 'jets/data'\n",
    "event_filename = jet_data_dir + '/' + 'events.root'\n",
    "event_treename = 'eventTree'\n",
    "event_tree_ur = ur.open(event_filename)[event_treename]\n",
    "\n",
    "event_tree_keys =[x.decode('utf-8') for x in event_tree_ur.keys()]\n",
    "for layer in layers: assert(layer in event_tree_keys)\n",
    "    \n",
    "# Get our calo images from the ROOT file.\n",
    "calo_images =  {layer:event_tree_ur.array(layer) for layer in layers}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Adding network scores to clusters in events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our event tree, where each entry corresponds with a *full event* -- a collection of topo-clusters.\n",
    "\n",
    "Now we want to evaluate some networks on the events' topo-clusters, and tack on the scores to our data.\n",
    "\n",
    "**TODO**: This setup works nicely for models being applied to a single branch. Can this be nicely extended to models that use multiple branches as input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "# Setup for TensorFlow and Keras.\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # disable some of the tensorflow info printouts, only display errors\n",
    "ngpu = 1\n",
    "gpu_list = [\"/gpu:\"+str(i) for i in range(ngpu)]\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy(devices=gpu_list)\n",
    "ngpu = strategy.num_replicas_in_sync\n",
    "print ('Number of devices: {}'.format(ngpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EMB1_NN ... Done.\n",
      "Loading EMB2_NN ... Done.\n",
      "Loading EMB3_NN ... Done.\n",
      "Loading TileBar0_NN ... Done.\n",
      "Loading TileBar1_NN ... Done.\n",
      "Loading TileBar2_NN ... Done.\n"
     ]
    }
   ],
   "source": [
    "classifier_prefix = path_prefix + 'classifier/Models' + '/'\n",
    "# Specify the networks we want to apply, which layers to evaluate them on, and where they are saved.\n",
    "# The key will ultimately give the name used in the ROOT file.\n",
    "networks = {\n",
    "    'EMB1_NN':     {'layers':['EMB1'],     'file':classifier_prefix + 'model_EMB1_flat_do20.h5'},\n",
    "    'EMB2_NN':     {'layers':['EMB2'],     'file':classifier_prefix + 'model_EMB2_flat_do20.h5'},\n",
    "    'EMB3_NN':     {'layers':['EMB3'],     'file':classifier_prefix + 'model_EMB3_flat_do20.h5'},\n",
    "    'TileBar0_NN': {'layers':['TileBar0'], 'file':classifier_prefix + 'model_TileBar0_flat_do20.h5'},\n",
    "    'TileBar1_NN': {'layers':['TileBar1'], 'file':classifier_prefix + 'model_TileBar1_flat_do20.h5'},\n",
    "    'TileBar2_NN': {'layers':['TileBar2'], 'file':classifier_prefix + 'model_TileBar2_flat_do20.h5'}\n",
    "}\n",
    "\n",
    "# Make sure our network branch names don't conflict with existing branch names,\n",
    "# and that they're being applied to images that exist.\n",
    "for key in networks.keys(): \n",
    "    assert(key not in event_tree_keys)\n",
    "    for element in networks[key]['layers']:\n",
    "        assert(element in layers)\n",
    "        \n",
    "network_models = {}\n",
    "for key in networks.keys():\n",
    "    print('Loading ' + str(key) + ' ...',end='')\n",
    "    network_models[key] = tf.keras.models.load_model(networks[key]['file'])\n",
    "    print(' Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating network: EMB1_NN\n",
      "Evaluating network: EMB2_NN\n",
      "Evaluating network: EMB3_NN\n",
      "Evaluating network: TileBar0_NN\n",
      "Evaluating network: TileBar1_NN\n",
      "Evaluating network: TileBar2_NN\n"
     ]
    }
   ],
   "source": [
    "model_scores = {}\n",
    "if(path_prefix not in sys.path): sys.path.append(path_prefix)\n",
    "from util import event_util as eu\n",
    "\n",
    "nevents = event_tree_ur.numentries\n",
    "for key, entry in networks.items():\n",
    "    input_layers = entry['layers']\n",
    "    if(len(input_layers) > 1):\n",
    "        print('Multi-layer NN\\'s not yet implemented. Skipping ' + str(key) + '.')\n",
    "        continue\n",
    "    \n",
    "    print('Evaluating network: ' + str(key))\n",
    "    input_layer = input_layers[0]    \n",
    "    model_input = eu.setupCells(calo_images,input_layer)\n",
    "    model_scores[key] = network_models[key].predict(model_input)\n",
    "    \n",
    "    # TODO: possibly reshape the output immediately, before tree fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShapeToString(shape):\n",
    "    l = len(shape)\n",
    "    shape_string = ''\n",
    "    for i in range(l): shape_string += '[' + str(shape[i]) + ']'\n",
    "    return shape_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO*: Add the network scores back to `eventTree`. This can be accomplished via a friend tree and a sequential loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(path_prefix not in sys.path): sys.path.append(path_prefix)\n",
    "from  util import qol_util as qu\n",
    "\n",
    "event_file = rt.TFile(event_filename,'UPDATE')\n",
    "event_tree = event_file.Get(event_treename)\n",
    "\n",
    "event_tree.SetBranchStatus('*',0)\n",
    "event_tree.SetBranchStatus('eventNumber',1)\n",
    "event_tree.SetBranchStatus('nCluster',1)\n",
    "nevents = event_tree.GetEntriesFast()\n",
    "\n",
    "# Get the maximum number of clusters per event\n",
    "rt.gROOT.SetBatch(True)\n",
    "event_tree.Draw('nCluster')\n",
    "h = rt.gPad.GetPrimitive('htemp')\n",
    "max_nCluster = int(h.GetXaxis().GetBinCenter(h.FindLastBinAbove(0)))\n",
    "rt.gROOT.SetBatch(False)\n",
    " \n",
    "for model in model_scores.keys():\n",
    "    t = rt.TTree(model,model)\n",
    "    \n",
    "    # prepare our branches. TODO: make this more flexible?\n",
    "    branch_buffer = {\n",
    "        'eventNumber':[np.zeros(1,dtype=np.dtype('i8')),'eventNumber/I'],\n",
    "        'nCluster':[np.zeros(1,dtype=np.dtype('i2')),'nCluster/S'],\n",
    "    }\n",
    "    model_shape_string = '[nCluster]' + ShapeToString(list(model_scores[model].shape)[1:])\n",
    "    model_shape = tuple([max_nCluster] + list(model_scores[model].shape)[1:])\n",
    "    branch_buffer[model] = [np.zeros(model_shape,dtype=np.dtype('f8')), model + model_shape_string + '/D']\n",
    "    \n",
    "    for name, branch in branch_buffer.items(): t.Branch(name,branch[0],branch[1])\n",
    "    cluster_iterator = 0\n",
    "    for i in range(nevents):\n",
    "        event_tree.GetEntry(i)\n",
    "        \n",
    "        branch_buffer['eventNumber'][0][0] = event_tree.eventNumber\n",
    "        branch_buffer['nCluster'][0][0] = event_tree.nCluster\n",
    "        \n",
    "        for j in range(event_tree.nCluster):\n",
    "            branch_buffer[model][0][j,:] = model_scores[model][cluster_iterator,:]\n",
    "            cluster_iterator += 1\n",
    "        t.Fill()\n",
    "    t.Write(model,rt.TObject.kOverwrite)    \n",
    "event_file.Close()\n",
    "\n",
    "# # Explicitly make the trees friends of the event tree TODO: This is not doing anything\n",
    "# event_file = rt.TFile(event_filename,'UPDATE')\n",
    "# event_tree = event_file.Get(event_treename)\n",
    "# for model in model_scores.keys(): event_tree.AddFriend(model,event_file)\n",
    "# event_file.Close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Jet clustering\n",
    "\n",
    "\n",
    "Now that we have things grouped by event, we should cluster the topo-clusters in each event into jets.\n",
    "\n",
    "We have a few possible ways of doing this:\n",
    "\n",
    "- `fastjet`\n",
    "    - We can use the Pythonic interface. It might be fast, however it takes Python lists of `fastjet.Pseudojet` objects as inputs to clustering and I'm not sure if building these will slow us down or not. Documentation is not very good.\n",
    "    \n",
    "- `pyjet`\n",
    "    - The 3rd-party interface between `fastjet` and `numpy`. Seems elegant but setup with external `fastjet` -- needed for the fastest clustering -- doesn't seem to work. Instructions are outdated and the project hasn't been updated in nearly a year.\n",
    "    \n",
    "- `TPythia8`\n",
    "    - Though it's kind of a hack, our `ROOT` installation from conda includes `pythia8` + `TPythia8`, which gives access to its `SlowJet` object. Despite the name this actually employs `fastjet` core as of a few versions ago so it's fast. It takes `Pythia8.event` objects as input, but we can artificially construct these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing fastjet Python library, which should be made by our setup script\n",
    "fj_dir = path_prefix + '/setup/fastjet/fastjet-install/lib/python3.8/site-packages'\n",
    "sys.path.append(fj_dir)\n",
    "import fastjet as fj\n",
    "\n",
    "print(fj.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jet clustering params\n",
    "R = 0.4\n",
    "jet_def = fj.JetDefinition(fj.antikt_algorithm, R)\n",
    "event_jets = []\n",
    "\n",
    "# Open our events file, and perform jet clustering using fastjet\n",
    "f = rt.TFile(jet_data_dir + '/' + 'events.root','read')\n",
    "t = f.Get('events')\n",
    "\n",
    "# only activate the branches we need for clustering\n",
    "tbranches = t.GetListOfBranches()\n",
    "active_branches = ['nCluster','clusterPt', 'clusterEta','clusterPhi','clusterE']\n",
    "t.SetBranchStatus('*',0)\n",
    "for branch in active_branches: t.SetBranchStatus(branch,1)\n",
    "\n",
    "vec_polar = rt.Math.PtEtaPhiEVector()\n",
    "nevents = t.GetEntriesFast()\n",
    "\n",
    "stride = 1000\n",
    "l = int(nevents/stride)\n",
    "bar_length = 50\n",
    "prefix = 'Performing jet clustering:'\n",
    "qu.printProgressBarColor(0, l, prefix=prefix, suffix='Complete', length=bar_length)\n",
    "\n",
    "for i in range(nevents):\n",
    "    t.GetEntry(i)\n",
    "    \n",
    "    nCluster = t.nCluster\n",
    "    particles = nCluster * [fj.PseudoJet(0.,0.,0.,0.)]\n",
    "    for j in range(nCluster):\n",
    "        vec_polar.SetCoordinates(t.clusterPt[j],t.clusterEta[j],t.clusterPhi[j],t.clusterE[j])\n",
    "        pj = fj.PseudoJet(vec_polar.Px(), vec_polar.Py(), vec_polar.Pz(), vec_polar.E()) # fastjet uses Cartesian\n",
    "        particles[j] = pj\n",
    "    event_jets.append(jet_def(particles))\n",
    "    \n",
    "    if(i%stride == 0): qu.printProgressBarColor(int(i/stride), l, prefix=prefix, suffix='Complete', length=bar_length)\n",
    "qu.printProgressBarColor(l, l, prefix=prefix, suffix='Complete', length=bar_length)\n",
    "\n",
    "f.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now make a TTree containing the jet info.\n",
    "njets_max = np.max(np.array([len(x) for x in event_jets],dtype=np.dtype('i2')))\n",
    "\n",
    "f = rt.TFile(jet_data_dir + '/' + 'events.root','update')\n",
    "t = rt.TTree('jets','jets')\n",
    "\n",
    "branch_buffer = {\n",
    "    'nJet': [np.zeros(1,dtype=np.dtype('i2')), 'nJet/S'],\n",
    "    'jetPt': [np.zeros(njets_max,dtype=np.dtype('f8')), 'jetPt[nJet]/D'],\n",
    "    'jetEta': [np.zeros(njets_max,dtype=np.dtype('f8')), 'jetEta[nJet]/D'],\n",
    "    'jetPhi': [np.zeros(njets_max,dtype=np.dtype('f8')), 'jetPhia[nJet]/D'],\n",
    "    'jetE': [np.zeros(njets_max,dtype=np.dtype('f8')), 'jetE[nJet]/D']\n",
    "}\n",
    "for key,val in branch_buffer.items(): t.Branch(key,val[0],val[1])\n",
    "stride = 1000\n",
    "l = int(nevents/stride)\n",
    "prefix = 'Writing jets to file:'\n",
    "\n",
    "qu.printProgressBarColor(0, l, prefix=prefix, suffix='Complete', length=bar_length)\n",
    "for i in range(nevents):\n",
    "    n = len(event_jets[i])\n",
    "    branch_buffer['nJet'][0][0] = n\n",
    "    for j in range(n):\n",
    "        branch_buffer['jetPt'][0][j] = event_jets[i][j].pt()\n",
    "        branch_buffer['jetEta'][0][j] = event_jets[i][j].eta()\n",
    "        branch_buffer['jetPhi'][0][j] = event_jets[i][j].phi()\n",
    "        branch_buffer['jetE'][0][j] = event_jets[i][j].e()\n",
    "    t.Fill()\n",
    "    \n",
    "    if(i%stride == 0): qu.printProgressBarColor(int(i/stride), l, prefix=prefix, suffix='Complete', length=bar_length)\n",
    "    \n",
    "t.Write('',rt.TObject.kOverwrite)\n",
    "qu.printProgressBarColor(l, l, prefix=prefix, suffix='Complete', length=bar_length)\n",
    "f.Close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code below here is unused/testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Little RDataFrame demo.\n",
    "\n",
    "a = range(10)\n",
    "b = np.random.rand(10)\n",
    "df = ROOT.RDataFrame(10)\n",
    "df = df.Define(\"x\", 'auto to_eval = std::string(\"a[\") + std::to_string(rdfentry_) + \"]\"; return float(TPython::Eval(to_eval.c_str()));')\n",
    "df = df.Define(\"y\", 'auto to_eval = std::string(\"b[\") + std::to_string(rdfentry_) + \"]\"; return float(TPython::Eval(to_eval.c_str()));')\n",
    "display = df.Display()\n",
    "display.Print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check showing that clusterIndex is not unique between files.\n",
    "trees = {key:file.Get(tree_name) for key, file in files.items()}\n",
    "t1 = trees['piminus']\n",
    "t2 = trees['piplus']\n",
    "\n",
    "t1_range = range(3,6)\n",
    "t2_range = range(316,318)\n",
    "\n",
    "for i in t1_range:\n",
    "    t1.GetEntry(i)\n",
    "    print(t1.eventNumber,'\\t',t1.clusterIndex)\n",
    "\n",
    "print('---')\n",
    "for i in t2_range:\n",
    "    t2.GetEntry(i)\n",
    "    print(t2.eventNumber,'\\t',t2.clusterIndex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml4p]",
   "language": "python",
   "name": "conda-env-ml4p-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
