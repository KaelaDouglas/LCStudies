{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jet Clustering\n",
    "\n",
    "This workflow is for use with the jet samples, that contain both `ClusterTree` and `EventTree` (provided by the `MLTree` utility). This **cannot** handle data where the `EventTree` does not exist, because that contains info on piecing the clusters together into events*, and the baseline jet clustering.\n",
    "\n",
    "\\* This pieceing together can be accomplished in workflows like `EventReconstructionPion.ipynb` but it's rather complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO:\n",
    "\n",
    "- jet clustering\n",
    "- comparison of jets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Setup\n",
    "\n",
    "First, let's import a bunch of packages we know we'll need right off-the-bat.\n",
    "\n",
    "Note that as we've set up our environment with `conda`, our `ROOT` installation has all the bells and whistles. This includes the `pythia8` library and its associated `ROOT` wrapper, `TPythia8`. We can optionally use this for jet-clustering, as it comes `fj-core`.\n",
    "Alternatively we could use the Pythonic interface for `fastjet` or [pyjet](https://github.com/scikit-hep/pyjet), but the latter requires linking an external fastjet build for speed and this doesn't seem to work when following their documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports - generic stuff\n",
    "\n",
    "import numpy as np\n",
    "import ROOT as rt\n",
    "import uproot as ur\n",
    "import sys, os, glob, uuid\n",
    "import subprocess as sub\n",
    "from pathlib import Path\n",
    "\n",
    "path_prefix = '/workspace/LCStudies/'\n",
    "if(path_prefix not in sys.path): sys.path.append(path_prefix)\n",
    "from util import ml_util as mu # for passing calo images to regression networks\n",
    "from util import qol_util as qu # for progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup for TensorFlow and Keras.\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # disable some of the tensorflow info printouts, only display errors\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ngpu = 1\n",
    "gpu_list = [\"/gpu:\"+str(i) for i in range(ngpu)]\n",
    "strategy = tf.distribute.MirroredStrategy(devices=gpu_list)\n",
    "ngpu = strategy.num_replicas_in_sync\n",
    "print ('Number of devices: {}'.format(ngpu))\n",
    "\n",
    "# Dictionary for storing all our neural network models that will be evaluated\n",
    "network_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup paths\n",
    "data_dir = path_prefix + 'data/jet'\n",
    "classification_dir = path_prefix + 'classifier/Models'\n",
    "regression_dir = path_prefix + 'regression/Models'\n",
    "fj_dir = path_prefix + '/setup/fastjet/fastjet-install/lib/python3.8/site-packages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Calorimeter meta-data -----\n",
    "layers = [\"EMB1\", \"EMB2\", \"EMB3\", \"TileBar0\", \"TileBar1\", \"TileBar2\"]\n",
    "nlayers = len(layers)\n",
    "cell_size_phi = [0.098, 0.0245, 0.0245, 0.1, 0.1, 0.1]\n",
    "cell_size_eta = [0.0031, 0.025, 0.05, 0.1, 0.1, 0.2]\n",
    "len_phi = [4, 16, 16, 4, 4, 4]\n",
    "len_eta = [128, 16, 8, 4, 4, 2]\n",
    "assert(len(len_phi) == nlayers)\n",
    "assert(len(len_eta) == nlayers)\n",
    "meta_data = {\n",
    "    layers[i]:{\n",
    "        'cell_size':(cell_size_eta[i],cell_size_phi[i]),\n",
    "        'dimensions':(len_eta[i],len_phi[i])\n",
    "    }\n",
    "    for i in range(nlayers)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat classifiers\n",
    "print('Loading flat classification models... ')\n",
    "flat_model_files = glob.glob(classification_dir + '/flat/' + '*.h5')\n",
    "flat_model_files.sort()\n",
    "flat_model_names = []\n",
    "for model in flat_model_files:\n",
    "    model_name = model.split('model_')[-1].split('_flat')[0]\n",
    "    print('\\tLoading ' + model_name + '... ',end='')\n",
    "    flat_model_names.append(model_name)\n",
    "    network_models[model_name] = tf.keras.models.load_model(model)\n",
    "    print('Done.')\n",
    "\n",
    "# combo classifier\n",
    "print('Loading simple combo classification model... ',end='')\n",
    "combo_model_file = classification_dir + '/simple/' + 'model_simple_do20.h5'\n",
    "network_models['combo'] = tf.keras.models.load_model(combo_model_file)\n",
    "print('Done.')\n",
    "\n",
    "# energy regression networks\n",
    "print('Loading charged-pion energy regression model... ',end='')\n",
    "charged_energy_model_file = regression_dir + '/' + 'all_charged.h5'\n",
    "network_models['e_charged'] = tf.keras.models.load_model(charged_energy_model_file)\n",
    "print('Done.')\n",
    "\n",
    "print('Loading neutral-pion energy regression model... ',end='')\n",
    "neutral_energy_model_file = regression_dir + '/' + 'all_neutral.h5'\n",
    "network_models['e_neutral'] = tf.keras.models.load_model(neutral_energy_model_file)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make a \"local\" copy of the jet data. We will only copy over certain branches, and we will skip any files that don't contain an `eventTree` in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filenames = glob.glob(data_dir + '/' + '*.root')\n",
    "\n",
    "# debugging - lets us use a single file to speed stuff up a lot.\n",
    "#data_filenames = [data_dir + '/' + 'user.angerami.21685345.OutputStream._000062.root']\n",
    "\n",
    "# our \"local\" data dir, where we create modified data files\n",
    "jet_data_dir = path_prefix + 'jets/data'\n",
    "Path(jet_data_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Get the original data.\n",
    "files = {name:rt.TFile(name,'READ') for name in data_filenames}\n",
    "\n",
    "# Some data files might be missing an EventTree.\n",
    "# For now, we will skip these because our methods count on an existing EventTree.\n",
    "delete_keys = []\n",
    "for key, val in files.items():\n",
    "    file_keys = [x.GetName() for x in val.GetListOfKeys()]\n",
    "    if('ClusterTree' not in file_keys or 'EventTree' not in file_keys):\n",
    "        delete_keys.append(key)\n",
    "\n",
    "for key in delete_keys: \n",
    "    print('Ignoring file:',key,'(no EventTree/ClusterTree found).')\n",
    "    del files[key]\n",
    "\n",
    "if(path_prefix not in sys.path): sys.path.append(path_prefix)\n",
    "from  util import qol_util as qu # for progress bar\n",
    "\n",
    "# now we make a local copy of the files in the jet_data_dir, keeping only certain branches\n",
    "active_branches = {}\n",
    "active_branches['cluster'] = [\n",
    "    'runNumber',\n",
    "    'eventNumber',\n",
    "    'truthE',\n",
    "    'truthPt',\n",
    "    'truthEta',\n",
    "    'truthPhi',\n",
    "    'clusterIndex',\n",
    "    'nCluster',\n",
    "    'clusterE',\n",
    "    'clusterECalib',\n",
    "    'clusterPt',\n",
    "    'clusterEta',\n",
    "    'clusterPhi',\n",
    "    'cluster_nCells',\n",
    "    'cluster_ENG_CALIB_TOT',\n",
    "    'EMB1',\n",
    "    'EMB2',\n",
    "    'EMB3',\n",
    "    'TileBar0',\n",
    "    'TileBar1',\n",
    "    'TileBar2'\n",
    "]\n",
    "active_branches['event'] = [\n",
    "    'runNumber',\n",
    "    'eventNumber',\n",
    "    'lumiBlock',\n",
    "    'NPV',\n",
    "    'nTruthPart',\n",
    "    'clusterCount',\n",
    "    'nCluster',\n",
    "    'clusterE',\n",
    "    'clusterPt',\n",
    "    'clusterEta',\n",
    "    'clusterPhi',\n",
    "    'AntiKt4EMTopoJetsPt',\n",
    "    'AntiKt4EMTopoJetsEta',\n",
    "    'AntiKt4EMTopoJetsPhi',\n",
    "    'AntiKt4EMTopoJetsE',\n",
    "    'AntiKt4LCTopoJetsPt',\n",
    "    'AntiKt4LCTopoJetsEta',\n",
    "    'AntiKt4LCTopoJetsPhi',\n",
    "    'AntiKt4LCTopoJetsE',\n",
    "    'AntiKt4TruthJetsPt',\n",
    "    'AntiKt4TruthJetsEta',\n",
    "    'AntiKt4TruthJetsPhi',\n",
    "    'AntiKt4TruthJetsE'\n",
    "]\n",
    "\n",
    "tree_names = {'cluster':'ClusterTree','event':'EventTree'}\n",
    "data_filenames = []\n",
    "\n",
    "l = len(files.keys())\n",
    "i = 0\n",
    "qu.printProgressBarColor(i, l, prefix='Copying data files:', suffix='Complete', length=50)\n",
    "\n",
    "for path, tfile in files.items():\n",
    "    filename_new = jet_data_dir + '/' + path.split('/')[-1]\n",
    "    old_trees = {x:tfile.Get(tree_names[x]) for x in tree_names.keys()}\n",
    "    \n",
    "    for key, tree in old_trees.items():\n",
    "        tree.SetBranchStatus('*',0)\n",
    "        for bname in active_branches[key]: tree.SetBranchStatus(bname,1)\n",
    "    \n",
    "    tfile_new = rt.TFile(filename_new,'RECREATE')\n",
    "    new_trees = {x:old_trees[x].CloneTree() for x in old_trees.keys()}\n",
    "    tfile_new.Write()\n",
    "    data_filenames.append(filename_new)\n",
    "    i += 1\n",
    "    qu.printProgressBarColor(i, l, prefix='Copying data files:', suffix='Complete', length=50)\n",
    "    del old_trees\n",
    "    del new_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the files & trees with uproot\n",
    "tree_names = {'cluster':'ClusterTree','event':'EventTree'}\n",
    "ur_trees = {file:{tree_key:ur.open(file)[tree_name] for tree_key,tree_name in tree_names.items()} for file in data_filenames}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will loop over our data files. This isn't the most notebook-esque code, but it should avoid \"out of memory\" issues: As we are dealing with a large amount of data, preparing all the data in memory before operating on it will result in very high memory usage. Thus we will sacrifice a multi-cell approach of preparing all the data step-by-step, in order to make sure we don't load more stuff into memory at a time than we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# branch buffer for filling our score trees\n",
    "    # make our branch buffer\n",
    "branch_buffer = {\n",
    "    'charged_likelihood_combo': np.zeros(1,dtype=np.dtype('f8')),\n",
    "    'clusterE_charged': np.zeros(1,dtype=np.dtype('f8')),\n",
    "    'clusterE_neutral': np.zeros(1,dtype=np.dtype('f8'))\n",
    "}\n",
    "\n",
    "for dfile, trees in ur_trees.items():\n",
    "    \n",
    "    print (dfile)\n",
    "    # prep the calo images\n",
    "    print('\\tPrepping calo images...')\n",
    "    calo_images = {}\n",
    "    for layer in layers:\n",
    "        calo_images[layer] = mu.setupCells(trees['cluster'],layer)\n",
    "    combined_images = np.concatenate(tuple([calo_images[layer] for layer in layers]), axis=1)\n",
    "\n",
    "    # prep some extra combined input for energy regression\n",
    "    print('\\tPrepping extra inputs...')\n",
    "    scaler_e = StandardScaler()\n",
    "    scaler_cal = StandardScaler()\n",
    "    scaler_eta = StandardScaler()\n",
    "    \n",
    "    e = trees['cluster'].array('clusterE')\n",
    "    e_calib = trees['cluster'].array('cluster_ENG_CALIB_TOT')\n",
    "    eta = trees['cluster'].array('clusterEta')\n",
    "    \n",
    "    # cleaning for e and e_calib (empirically needed for e_calib to remove values that are too large)\n",
    "    epsilon = 1.0e-12\n",
    "    e = np.where(e < epsilon, epsilon, e)\n",
    "    e_calib = np.where(e_calib < epsilon, epsilon, e_calib)\n",
    "    \n",
    "    regression_cols = {}\n",
    "    regression_cols['s_logE'] = scaler_e.fit_transform(np.log(e).reshape(-1,1))\n",
    "    regression_cols['s_logECalib'] = scaler_cal.fit_transform(np.log(e_calib).reshape(-1,1))\n",
    "    regression_cols['s_eta'] = scaler_eta.fit_transform(eta.reshape(-1,1))\n",
    "    \n",
    "    s_combined,scaler_combined = mu.standardCells(combined_images, layers)\n",
    "    regression_input = np.column_stack((regression_cols['s_logE'], regression_cols['s_eta'],s_combined))\n",
    "\n",
    "    # now find network scores\n",
    "    print('\\tCalculating network outputs...')\n",
    "    model_scores = {}\n",
    "    \n",
    "    print('\\t\\tClassification... ', end='')\n",
    "    # 1) flat networks\n",
    "    for layer in flat_model_names:\n",
    "        model = network_models[layer]\n",
    "        model_scores[layer] = model.predict(calo_images[layer])[:,1] # [:,1] based on Max's code, this is input to combo network. Likelihood of being charged (vs. neutral)\n",
    "    \n",
    "    # 2) combo network\n",
    "    name = 'combo'\n",
    "    model = network_models[name]\n",
    "    input_scores = np.column_stack([model_scores[layer] for layer in layers])\n",
    "    model_scores[name] = model.predict(input_scores)[:,1] # likelihood of being charged pion (versus neutral pion)\n",
    "    print('Done.')\n",
    "    \n",
    "    print('\\t\\tRegression... ', end='')\n",
    "    # 3) energy regression networks\n",
    "    name = 'e_charged'\n",
    "    model = network_models[name]\n",
    "    model_scores[name] = np.exp(scaler_cal.inverse_transform(model.predict(regression_input)))\n",
    "    \n",
    "    name = 'e_neutral'\n",
    "    model = network_models[name]\n",
    "    model_scores[name] = np.exp(scaler_cal.inverse_transform(model.predict(regression_input)))\n",
    "    print('Done.')\n",
    "    \n",
    "    # Now we should save these scores to a new tree.\n",
    "    f = rt.TFile(dfile, 'UPDATE')\n",
    "    tree_name = 'ScoreTree'\n",
    "    t = rt.TTree(tree_name, tree_name)\n",
    "    \n",
    "    print('Saving network scores to tree ' + tree_name + '... ',end='')    \n",
    "    # --- Setup the branches using our buffer. This is a rather general/flexible code block. ---\n",
    "    branches = {}\n",
    "    for bname, val in branch_buffer.items():\n",
    "        descriptor = bname\n",
    "        bshape = val.shape\n",
    "        if(bshape != (1,)):\n",
    "            for i in range(len(bshape)):\n",
    "                descriptor += '[' + str(bshape[i]) + ']'\n",
    "        descriptor += '/'\n",
    "        if(val.dtype == np.dtype('i2')): descriptor += 'S'\n",
    "        elif(val.dtype == np.dtype('i4')): descriptor += 'I'\n",
    "        elif(val.dtype == np.dtype('i8')): descriptor += 'L'\n",
    "        elif(val.dtype == np.dtype('f4')): descriptor += 'F'\n",
    "        elif(val.dtype == np.dtype('f8')): descriptor += 'D'\n",
    "        else:\n",
    "            print('Warning, setup issue for branch: ', key, '. Skipping.')\n",
    "            continue\n",
    "        branches[bname] = t.Branch(bname,val,descriptor)\n",
    "    \n",
    "    # Fill the model score tree, and save it to the local data file.\n",
    "    nentries = model_scores['combo'].shape[0]\n",
    "    for i in range(nentries):\n",
    "        branch_buffer['charged_likelihood_combo'][0] = model_scores['combo'][i]\n",
    "        branch_buffer['clusterE_charged'][0] = model_scores['e_charged'][i]\n",
    "        branch_buffer['clusterE_neutral'][0] = model_scores['e_neutral'][i]\n",
    "        t.Fill()\n",
    "    \n",
    "    t.Write(tree_name, rt.TObject.kOverwrite)\n",
    "    f.Close()\n",
    "    print('Done.')\n",
    "    \n",
    "tree_names['score'] = tree_name\n",
    "ur_trees = {file:{tree_key:ur.open(file)[tree_name] for tree_key,tree_name in tree_names.items()} for file in data_filenames}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to perform jet-clustering, where we'll use the regressed energies (and the classification score will tell us which regressed energy to use for each cluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_eta_cut = 0.3 # eta cut to be applied to all jets -- those we make and those we're given\n",
    "global_truth_e_cut = 25. # GeV -- recall that jet energies are stored in keV!\n",
    "\n",
    "# pavetext with info on our global eta cut\n",
    "cut_info = '|#eta_{j}| <' + ' {val:.1f}'.format(val=global_eta_cut)\n",
    "cut_pave = rt.TPaveText(0.7, 0.6, 0.9, 0.7, 'NDC')\n",
    "cut_pave.SetFillColor(0)\n",
    "cut_pave.SetBorderSize(0)\n",
    "cut_pave.SetTextFont(42)\n",
    "cut_pave.SetTextSize(0.04)\n",
    "cut_pave.SetTextAlign(12)\n",
    "cut_pave.AddText(cut_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(fj_dir)\n",
    "import fastjet as fj\n",
    "\n",
    "# Jet clustering params\n",
    "R = 0.4\n",
    "pt_min = 0.0 # min jet pT (GeV) (appears to be 5.0 GeV for the other jets but we turn it off for now)\n",
    "jet_def = fj.JetDefinition(fj.antikt_algorithm, R)\n",
    "eta_max = global_eta_cut\n",
    "\n",
    "#energy rescaling (all jet info is saved in MeV, cluster info is in GeV)\n",
    "energy_scaling = 1.0e3\n",
    "\n",
    "# classification threshold - scores below are considered neutral pion clusters, scores above are considered charged pion clusters\n",
    "classification_threshold = 0.5\n",
    "\n",
    "# branch buffer for our jet tree\n",
    "branch_buffer = {\n",
    "    'AntiKt4MLTopoJetsPt':rt.std.vector('float')(),\n",
    "    'AntiKt4MLTopoJetsEta':rt.std.vector('float')(),\n",
    "    'AntiKt4MLTopoJetsPhi':rt.std.vector('float')(),\n",
    "    'AntiKt4MLTopoJetsE':rt.std.vector('float')()\n",
    "}\n",
    "\n",
    "for dfile, trees in ur_trees.items():\n",
    "    \n",
    "    # event info\n",
    "    cluster_min = trees['event'].array('clusterCount') # naming convention is a bit funny! clusterCount gives event starting index in ClusterTree\n",
    "    cluster_max = cluster_min + trees['event'].array('nCluster') - 1\n",
    "    \n",
    "    # cluster info (pre-existing) #TODO; we include reco cluster E info for debugging purposes only\n",
    "    cluster_vec = np.column_stack(tuple(trees['cluster'].arrays(['clusterPt','clusterEta','clusterPhi','clusterE']).values()))\n",
    "    \n",
    "    # topo-cluster classifications for all of the clusters in this file\n",
    "    cluster_classification = trees['score'].array('charged_likelihood_combo')\n",
    "    \n",
    "    # topo-cluster regressed energies for all clusters in this file (regressions assuming cluster comes from charged/neutral pion)\n",
    "    cluster_energies = np.column_stack(tuple(trees['score'].arrays(['clusterE_charged','clusterE_neutral']).values()))\n",
    "    \n",
    "    # tree for saving jet info\n",
    "    f = rt.TFile(dfile, 'UPDATE')\n",
    "    tree_name = 'JetTree'\n",
    "    t = rt.TTree(tree_name, tree_name)\n",
    "    branches = {}\n",
    "    for key,val in branch_buffer.items():\n",
    "        branches[key] = t.Branch(key, val)\n",
    "    \n",
    "    vec_polar = rt.Math.PtEtaPhiEVector()    \n",
    "    # loop over events\n",
    "    nevents = trees['event'].numentries\n",
    "    for i in range(nevents):\n",
    "        \n",
    "        # explicit list of cluster indices we're working with -- these are indices in ClusterTree, corresponding to event i\n",
    "        cluster_idxs = np.linspace(cluster_min[i], cluster_max[i], cluster_max[i] - cluster_min[i] + 1, dtype=np.dtype('i8'))        \n",
    "        # nCluster = cluster_idxs.shape[0]\n",
    "                \n",
    "        pseudojets = []\n",
    "        for idx in cluster_idxs:\n",
    "            energy = cluster_energies[idx,0] # swap in the regressed energy, start off assuming a charged pion\n",
    "            if cluster_classification[idx] < classification_threshold: energy = cluster_energies[idx,1] # switch to neutral energy regression if dictated by classification\n",
    "            \n",
    "            # rescale the pT according to how we've changed the topo-cluster energy (don't touch eta, phi)\n",
    "            pt = cluster_vec[idx,0] * energy / cluster_vec[idx,3]\n",
    "            \n",
    "            # create 4-vector representing the topo-cluster\n",
    "            vec_polar.SetCoordinates(pt,cluster_vec[idx,1],cluster_vec[idx,2],energy)\n",
    "            \n",
    "            # make a fastjet PseudoJet object from this 4-vector, add it to the list that will be given to jet clustering\n",
    "            pseudojets.append(fj.PseudoJet(vec_polar.Px(), vec_polar.Py(), vec_polar.Pz(), vec_polar.E())) # fastjet uses Cartesian as input\n",
    "        \n",
    "        # perform jet clustering\n",
    "        jets = jet_def(pseudojets)\n",
    "        \n",
    "        # Apply optional minimum jet pT cut\n",
    "        jet_pt = np.array([jet.pt() for jet in jets])\n",
    "        jet_indices = np.linspace(0,len(jets)-1,len(jets),dtype=np.dtype('i8'))[jet_pt >= pt_min]\n",
    "        jets = [jets[i] for i in jet_indices]\n",
    "        \n",
    "        # Apply optional maximum |eta| cut\n",
    "        jet_eta = np.array([jet.eta() for jet in jets])\n",
    "        jet_indices = np.linspace(0,len(jets)-1,len(jets),dtype=np.dtype('i8'))[np.abs(jet_eta) <= eta_max]\n",
    "        jets = [jets[i] for i in jet_indices]\n",
    "\n",
    "        njets = len(jets)\n",
    "        # Save jet info to a TTree\n",
    "        for key in branch_buffer.keys(): branch_buffer[key].clear()\n",
    "            \n",
    "        for j in range(njets):    \n",
    "#             vec.SetCoordinates(jets[j].pt(), jets[j].eta(), jets[j].phi(), jets[j].e())\n",
    "#             print(vec.E(), vec.P(), vec.M())\n",
    "#             #print(jets[j].pt(), jets[j].e())\n",
    "            branch_buffer['AntiKt4MLTopoJetsPt'].push_back(jets[j].pt() * energy_scaling)\n",
    "            branch_buffer['AntiKt4MLTopoJetsEta'].push_back(jets[j].eta())\n",
    "            branch_buffer['AntiKt4MLTopoJetsPhi'].push_back(jets[j].phi())\n",
    "            branch_buffer['AntiKt4MLTopoJetsE'].push_back(jets[j].e() * energy_scaling)\n",
    "        \n",
    "        t.Fill()\n",
    "    t.Write(tree_name, rt.TObject.kOverwrite)\n",
    "    f.Close()\n",
    "\n",
    "tree_names['jet'] = tree_name\n",
    "ur_trees = {file:{tree_key:ur.open(file)[tree_name] for tree_key,tree_name in tree_names.items()} for file in data_filenames}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to match the jets we just clustered with the truth jets, to see how well we've reconstructed things.\n",
    "\n",
    "Here's how we will perform jet-matching:\n",
    "\n",
    "- Get the list of all reco jets and truth jets for an event\n",
    "- Loop through the truth jets\n",
    "    - Find the closest reco jet within $\\Delta R=0.3$, if it exists, and call it a match\n",
    "        - If we fail to find a match, make a note of this\n",
    "    - Take the matched reco jet off the list, so we don't match it a 2nd time\n",
    "    \n",
    "From matched jets, we will immediately compute $E_\\text{reco}/E_\\text{true}$ and histogram it (we will *not* be saving the matches directly to a file, for now).\n",
    "\n",
    "We will perform this process for all the different reco jet definitions in the files, so that we can compare our method's energy resolution to the others'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns pairs & lists of matched and unmatched indices. These indices are w.r.t.\n",
    "# whatever is given as input -- if some jets have been dropped from lists (for not passing cuts)\n",
    "# this will *not* be known to jet_matching(). (i.e. it will always work \n",
    "# internally with a set of sequential indices, with which it reports results.)\n",
    "\n",
    "def jet_matching(reco_jets, truth_jets, max_distance = 0.3):\n",
    "    ntruth = len(truth_jets['eta'])\n",
    "    nreco = len(reco_jets['eta'])\n",
    "    reco_indices = np.linspace(0, nreco, nreco + 1, dtype = np.dtype('i2'))\n",
    "    \n",
    "    #TLorentzVectors for computing deltaR\n",
    "    vec1 = rt.Math.PtEtaPhiEVector()\n",
    "    vec2 = rt.Math.PtEtaPhiEVector()\n",
    "\n",
    "    matched_indices = []\n",
    "    unmatched_truth = []\n",
    "    unmatched_reco = []\n",
    "    \n",
    "    for i in range(ntruth):\n",
    "        truth_eta = truth_jets['eta'][i]\n",
    "        truth_phi = truth_jets['phi'][i]\n",
    "        vec1.SetCoordinates(0.,truth_eta,truth_phi,0.)\n",
    "        \n",
    "        # get distances between this truth jet and all unmatched reco jets\n",
    "        distances = np.zeros(nreco)\n",
    "        for j in range(nreco):\n",
    "            reco_idx = reco_indices[j]\n",
    "            if(reco_idx < 0):\n",
    "                distances[j] = -999.\n",
    "                continue \n",
    "            vec2.SetCoordinates(0.,reco_jets['eta'][reco_idx],reco_jets['phi'][reco_idx],0.)\n",
    "            distances[j] = rt.Math.VectorUtil.DeltaR(vec1,vec2)\n",
    "            \n",
    "        # now find the minimum distance, beware of negative values\n",
    "        # see https://stackoverflow.com/a/37973409\n",
    "        valid_idx = np.where(distances >= 0.)[0]\n",
    "        \n",
    "        if(len(valid_idx) == 0):\n",
    "            unmatched_truth.append(i)\n",
    "            continue\n",
    "        \n",
    "        match_idx = valid_idx[distances[valid_idx].argmin()]\n",
    "        matched_indices.append((i, match_idx))\n",
    "        reco_indices[match_idx] = -1.\n",
    "    unmatched_reco = reco_indices[reco_indices > -1]\n",
    "    \n",
    "    return {'truth_reco':matched_indices, 'unmatched_truth':unmatched_truth, 'unmatched_reco':unmatched_reco}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Work in progress:** We'll save the reco jet matching information to a new tree. Note that this will take a little bit of time to compute, but saving it like this will allow quicker access later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving jet matching info to a new tree\n",
    "\n",
    "# branch_buffer = {\n",
    "#     'AntiKt4EMTopoJetsMatch':rt.std.vector('int')(),\n",
    "#     'AntiKt4LCTopoJetsMatch':rt.std.vector('int')(),\n",
    "#     'AntiKt4MLTopoJetsMatch':rt.std.vector('int')()\n",
    "# }\n",
    "\n",
    "# jet_definitions = {\n",
    "#     'EM':('event', 'AntiKt4EMTopoJets'),\n",
    "#     'LC':('event', 'AntiKt4LCTopoJets'),\n",
    "#     'ML':('jet',   'AntiKt4MLTopoJets'),\n",
    "#     'Truth':('event', 'AntiKt4TruthJets')\n",
    "# }\n",
    "\n",
    "# reco_jet_defs = ['EM','LC','ML']\n",
    "\n",
    "# for dfile, tree in ur_trees.items():\n",
    "        \n",
    "# #     # tree for saving jet matching info\n",
    "# #     f = rt.TFile(dfile, 'UPDATE')\n",
    "# #     tree_name = 'JetMatchTree'\n",
    "# #     t = rt.TTree(tree_name, tree_name)\n",
    "# #     branches = {}\n",
    "# #     for key,val in branch_buffer.items():\n",
    "# #         branches[key] = t.Branch(key, val)\n",
    "    \n",
    "#     # Determine which jets pass our global eta cut\n",
    "#     eta = {key:ur_trees[dfile][val[0]].array(val[1] + 'Eta') for key, val in jet_definitions.items()}\n",
    "#     jet_indices = {key: x <= global_eta_cut for key,x in eta.items()}\n",
    "    \n",
    "#     # Apply our truth jet energy cut. Recall that jets have things stored in keV for now, whereas the cut is in GeV.\n",
    "#     truth_energy = ur_trees[dfile][jet_definitions['Truth'][0]].array(jet_definitions['Truth'][1] + 'E')\n",
    "#     jet_indices['Truth'] = jet_indices['Truth'] * (truth_energy >= 1.0e3 * global_truth_e_cut)\n",
    "    \n",
    "#     # We will also need phi info for performing the matching\n",
    "#     phi = {key:ur_trees[dfile][val[0]].array(val[1] + 'Phi') for key, val in jet_definitions.items()}\n",
    "\n",
    "#     nevents = ur_trees[dfile]['event'].numentries\n",
    "#     for i in range(nevents):\n",
    "        \n",
    "#         # keep track of which indices are present and dropped\n",
    "#         jet_tree_indices = {key:np.linspace(0,len(jet_indices[key])-1,len(jet_indices[key]),dtype=np.dtype('i2'))[jet_indices[key]] for key in jet_indices.keys()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_max = 0.3\n",
    "\n",
    "reco_jet_definitions = {\n",
    "    'EM':('event', 'AntiKt4EMTopoJets'),\n",
    "    'LC':('event', 'AntiKt4LCTopoJets'),\n",
    "    'ML':('jet',   'AntiKt4MLTopoJets')\n",
    "}\n",
    "\n",
    "truth_jet_definition = 'AntiKt4TruthJets'\n",
    "jet_energy_ratios = {x:[] for x in reco_jet_definitions.keys()}\n",
    "\n",
    "for dfile in data_filenames:\n",
    "    nevents = ur_trees[dfile]['event'].numentries\n",
    "#     nevents = 10 #TODO: restricting range for debugging\n",
    "    for i in range(nevents):\n",
    "        \n",
    "        # take only jets passing our global eta cut\n",
    "        truth_eta = ur_trees[dfile]['event'].array(truth_jet_definition + 'Eta')[i]\n",
    "        truth_indices = np.linspace(0,len(truth_eta)-1,len(truth_eta),dtype=np.dtype('i8'))[np.abs(truth_eta) <= global_eta_cut]\n",
    "        \n",
    "        reco_eta = {key: ur_trees[dfile][jet_def[0]].array(jet_def[1] + 'Eta')[i] for key, jet_def in reco_jet_definitions.items()}\n",
    "        reco_indices = {key: np.linspace(0,len(eta)-1,len(eta),dtype=np.dtype('i8'))[np.abs(eta) <= global_eta_cut] for key, eta in reco_eta.items()}\n",
    "\n",
    "        truth_jets = {'eta':ur_trees[dfile]['event'].array(truth_jet_definition + 'Eta')[i][truth_indices],'phi':ur_trees[dfile]['event'].array(truth_jet_definition + 'Phi')[i][truth_indices]}\n",
    "        reco_jets = {key:{'eta':ur_trees[dfile][jet_def[0]].array(jet_def[1] + 'Eta')[i][reco_indices[key]],'phi':ur_trees[dfile][jet_def[0]].array(jet_def[1] + 'Phi')[i][reco_indices[key]]} for key, jet_def in reco_jet_definitions.items()}\n",
    "        \n",
    "        for key, jet_def in reco_jet_definitions.items():\n",
    "            matching_results = jet_matching(reco_jets[key], truth_jets, max_distance = R_max)\n",
    "            for match in matching_results['truth_reco']:\n",
    "                e_truth = ur_trees[dfile]['event'].array(truth_jet_definition + 'E')[i,match[0]]\n",
    "                e_reco = ur_trees[dfile][jet_def[0]].array(jet_def[1] + 'E')[i,match[0]]\n",
    "                e_ratio = e_reco / e_truth\n",
    "                jet_energy_ratios[key].append(e_ratio)\n",
    "                \n",
    "jet_energy_ratios = {key:np.array(val) for key,val in jet_energy_ratios.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetColor(hist, color, alpha = 0.5):\n",
    "    hist.SetLineColor(color)\n",
    "    hist.SetFillColorAlpha(color, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot results\n",
    "\n",
    "colors = {\n",
    "    'EM':rt.kGreen,\n",
    "    'LC':rt.kRed,\n",
    "    'ML':rt.kBlue\n",
    "}\n",
    "min_ratio = 0.\n",
    "max_ratio = 5.\n",
    "nbins = 50\n",
    "\n",
    "hists = {key: rt.TH1F(key + 'ratio', key + ';E_{reco}/E_{true};Count',nbins,min_ratio,max_ratio) for key in reco_jet_definitions.keys()}\n",
    "for key in colors.keys():\n",
    "    SetColor(hists[key],colors[key])\n",
    "    for entry in jet_energy_ratios[key]:\n",
    "        hists[key].Fill(entry)\n",
    "\n",
    "nbins_factor = 1\n",
    "mult_factor = 1.0e5\n",
    "hists2 = {key: rt.TH1F(key + 'ratio', key + ';E_{reco}/E_{true};Count',int(nbins_factor * nbins),min_ratio,mult_factor * max_ratio) for key in reco_jet_definitions.keys()}\n",
    "for key in colors.keys():\n",
    "    SetColor(hists2[key],colors[key])\n",
    "    for entry in jet_energy_ratios[key]:\n",
    "        hists2[key].Fill(entry)\n",
    "        \n",
    "c = rt.TCanvas('c_ratio','c_ratio',800,600)\n",
    "c2 = rt.TCanvas('c_ratio2','c_ratio2',800,600)\n",
    "\n",
    "rt.gStyle.SetOptStat(0)\n",
    "legend = rt.TLegend(0.7,0.7,0.9,0.85)\n",
    "legend.SetBorderSize(0)\n",
    "\n",
    "stack = rt.THStack('stack','Energy Ratio;E_{reco}/E_{truth};Count')\n",
    "stack2 = rt.THStack('stack2','Energy Ratio (extended axis);E_{reco}/E_{truth};Count')\n",
    "\n",
    "for key in hists.keys():\n",
    "    stack.Add(hists[key])\n",
    "    stack2.Add(hists2[key])\n",
    "    legend.AddEntry(hists[key],key,'f')\n",
    "\n",
    "c.cd()\n",
    "stack.Draw('NOSTACK HIST')\n",
    "legend.Draw()\n",
    "cut_pave.Draw()\n",
    "\n",
    "c2.cd()\n",
    "stack2.Draw('NOSTACK HIST')\n",
    "legend.Draw()\n",
    "cut_pave.Draw()\n",
    "c2.SetLogy()\n",
    "\n",
    "c.Draw()\n",
    "c2.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the stuff we're seeing above looks weird. Many of the cluster energies are too low, but there's also a very large tail to the distribution.\n",
    "\n",
    "Note that there seems to have been an issue with **units** that I have already accounted for: Based on the magnitude of their values, I think that the truth jets and existing reco jets (EM, LC) had their $p_T$ and energy values stored in keV, not GeV. I have adjusted the ML jets to store their info in keV too to match, and we will convert to GeV for all for plotting.\n",
    "\n",
    "But even with this rescaling having been done, we see issues such as in the plot above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification\n",
    "\n",
    "To get a better sense of what our data looks like, let's produce some kinematic plots for all flavors of jets. We'll see how the different jet definitions' kinematics compare, and if something is off with our ML jets.\n",
    "\n",
    "For our reco jets, we will only be considering those that have been matched with truth jets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawSet(hists, logx=False, logy=True, cut_pave = 0):\n",
    "    canvas = rt.TCanvas(str(uuid.uuid4()), str(uuid.uuid4()), 800, 600)\n",
    "    nx = 2\n",
    "    l = len(hists.keys())\n",
    "    ny = int(np.ceil(l / nx))\n",
    "    canvas.Divide(nx, ny)\n",
    "    for i, hist in enumerate(hists.values()):\n",
    "        canvas.cd(i+1)\n",
    "        hist.Draw('HIST')\n",
    "        if(logx):\n",
    "            rt.gPad.SetLogx()\n",
    "            hist.GetXaxis().SetRangeUser(1.0e-0, hist.GetXaxis().GetBinUpEdge(hist.GetXaxis().GetLast()))\n",
    "        if(logy): \n",
    "            rt.gPad.SetLogy()\n",
    "            hist.SetMinimum(5.0e-1)\n",
    "        else:\n",
    "            hist.SetMinimum(0.)\n",
    "        if(cut_pave != 0): cut_pave.Draw()\n",
    "            \n",
    "    return canvas\n",
    "\n",
    "# plotting various jet energies divided by pT\n",
    "jet_defs = {\n",
    "    'Truth':('event','AntiKt4TruthJets'),\n",
    "    'EM':('event', 'AntiKt4EMTopoJets'),\n",
    "    'LC':('event', 'AntiKt4LCTopoJets'),\n",
    "    'ML':('jet',   'AntiKt4MLTopoJets')\n",
    "}\n",
    "\n",
    "colors = {\n",
    "    'Truth': rt.kOrange,\n",
    "    'EM': rt.kGreen,\n",
    "    'LC': rt.kRed,\n",
    "    'ML': rt.kBlue\n",
    "}\n",
    "\n",
    "scale_factors = 0.001 # jet info seems to be in keV, we want to plot it all in GeV\n",
    "\n",
    "energy_hists = {key:rt.TH1F(str(uuid.uuid4()), key + ' Jets;Energy [GeV];Count', 100, 0., 500.) for key in jet_defs.keys()}\n",
    "pt_hists     = {key:rt.TH1F(str(uuid.uuid4()), key + ' Jets;p_{T} [GeV];Count', 30, 0., 150.) for key in jet_defs.keys()}\n",
    "eta_hists    = {key:rt.TH1F(str(uuid.uuid4()), key + ' Jets;#eta;Count', 50, -1., 1.) for key in jet_defs.keys()}\n",
    "m_hists      = {key:rt.TH1F(str(uuid.uuid4()), key + ' Jets;m [GeV];Count', 45, -250., 2000.) for key in jet_defs.keys()}\n",
    "ep_hists     = {key:rt.TH1F(str(uuid.uuid4()), key + ' Jets;Energy / p_{T};Count', 50, 0., 5.) for key in jet_defs.keys()}\n",
    "n_hists      = {key:rt.TH1I(str(uuid.uuid4()), key + ' Jets;N_{jets};Count', 100, 0., 100) for key in jet_defs.keys()}\n",
    "\n",
    "vec = rt.Math.PtEtaPhiEVector()\n",
    "for dfile in data_filenames:\n",
    "    for key, jet_def in jet_defs.items():\n",
    "        \n",
    "        eta         =                 ur_trees[dfile][jet_def[0]].array(jet_def[1] + 'Eta')\n",
    "        n           = [len(x[np.abs(x) < global_eta_cut]) for x in eta]\n",
    "        eta         = eta.flatten()\n",
    "        jet_indices = np.linspace(0,len(eta)-1,len(eta),dtype=np.dtype('i8'))[np.abs(eta) <= global_eta_cut]\n",
    "        eta         = eta[jet_indices]\n",
    "        energy      = scale_factors * ur_trees[dfile][jet_def[0]].array(jet_def[1] + 'E').flatten()[jet_indices]\n",
    "        pt          = scale_factors * ur_trees[dfile][jet_def[0]].array(jet_def[1] + 'Pt').flatten()[jet_indices]\n",
    "        ep          = energy / pt\n",
    "#         n           = np.array([x.shape[0] for x in ur_trees[dfile][jet_def[0]].array(jet_def[1] + 'E')],dtype=np.dtype('i2'))\n",
    "\n",
    "#         print('Minimum pT for ' + key + ' = ' + str(np.min(pt)))\n",
    "#         print('\\tCorresponding energy =',energies[np.argmin(pt)])\n",
    "        for i in range(len(n)):\n",
    "            n_hists[key].Fill(n[i])\n",
    "        for i in range(len(ep)):\n",
    "            energy_hists[key].Fill(energy[i])\n",
    "            pt_hists[key].Fill(pt[i])\n",
    "            eta_hists[key].Fill(eta[i])\n",
    "            ep_hists[key].Fill(ep[i])\n",
    "            vec.SetCoordinates(pt[i],eta[i],0.,energy[i])\n",
    "            m_hists[key].Fill(vec.M())\n",
    "\n",
    "hist_lists = [energy_hists, pt_hists, eta_hists, ep_hists, m_hists, n_hists]\n",
    "for key in jet_defs.keys():\n",
    "    for hist_list in hist_lists:\n",
    "        SetColor(hist_list[key],colors[key])            \n",
    "            \n",
    "rt.gStyle.SetOptStat(0)\n",
    "canvases = []\n",
    "\n",
    "for hist_list in hist_lists:\n",
    "    logx = False\n",
    "#     if(hist_list == energy_hists): logx=True\n",
    "    c = DrawSet(hist_list, logx=logx, cut_pave = cut_pave)\n",
    "    canvases.append(c)\n",
    "    c.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our jet-finding, using the regressed energies, is producing a significant number of ML jets with negative mass. I think this is really just a result of the input energies being too low (so that $p^2 > E^2$). Besides the peak of the $m$ distribution being below zero for the ML jets, we also see this weird behavior exhibited in our plot of $E/p_T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying jet clustering\n",
    "\n",
    "There are two things we can do to make sure that clustering is working as intended:\n",
    "- Reproducing the EM jets.\n",
    "- Flipping the classification of clusters to produce new ML jets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Reproducing EM jets\n",
    "\n",
    "This code will look a lot like our jet clustering above, but we will be using the default reco energy. We'll save our new EM jets to a tree called `JetTree_EM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(fj_dir)\n",
    "import fastjet as fj\n",
    "\n",
    "# Jet clustering params\n",
    "R = 0.4\n",
    "pt_min = 0.0 # min jet pT (GeV) (appears to be 5.0 GeV for the other jets but we turn it off for now)\n",
    "jet_def = fj.JetDefinition(fj.antikt_algorithm, R)\n",
    "\n",
    "#energy rescaling (all jet info is saved in keV, not GeV)\n",
    "energy_scaling = 1.0e3\n",
    "\n",
    "# branch buffer for our jet tree\n",
    "branch_buffer = {\n",
    "    'AntiKt4EMTopoJetsPt':rt.std.vector('float')(),\n",
    "    'AntiKt4EMTopoJetsEta':rt.std.vector('float')(),\n",
    "    'AntiKt4EMTopoJetsPhi':rt.std.vector('float')(),\n",
    "    'AntiKt4EMTopoJetsE':rt.std.vector('float')()\n",
    "}\n",
    "\n",
    "for dfile, trees in ur_trees.items():\n",
    "    \n",
    "    # event info\n",
    "    cluster_min = trees['event'].array('clusterCount')\n",
    "    cluster_max = cluster_min + trees['event'].array('nCluster') - 1\n",
    "    \n",
    "    # cluster info (pre-existing)\n",
    "    cluster_vec = np.column_stack(tuple(trees['cluster'].arrays(['clusterPt','clusterEta','clusterPhi','clusterE']).values()))\n",
    "#     cluster_vec = np.column_stack(tuple(trees['cluster'].arrays(['clusterPt','clusterEta','clusterPhi','cluster_ENG_CALIB_TOT']).values()))\n",
    "\n",
    "\n",
    "    # tree for saving jet info\n",
    "    f = rt.TFile(dfile, 'UPDATE')\n",
    "    tree_name = 'JetTree_EM'\n",
    "    t = rt.TTree(tree_name, tree_name)\n",
    "    \n",
    "    branches = {}\n",
    "    for key,val in branch_buffer.items():\n",
    "        branches[key] = t.Branch(key, val)\n",
    "    \n",
    "    vec_polar = rt.Math.PtEtaPhiEVector()    \n",
    "    # loop over events\n",
    "    nevents = trees['event'].numentries\n",
    "    for i in range(nevents):\n",
    "        cluster_idxs = np.linspace(cluster_min[i], cluster_max[i], cluster_max[i] - cluster_min[i] + 1, dtype=np.dtype('i8'))        \n",
    "        nCluster = cluster_idxs.shape[0]\n",
    "                \n",
    "        pseudojets = []\n",
    "        for j, idx in enumerate(cluster_idxs):\n",
    "            vec_polar.SetCoordinates(cluster_vec[idx,0],cluster_vec[idx,1],cluster_vec[idx,2],cluster_vec[idx,3])\n",
    "            pseudojets.append(fj.PseudoJet(vec_polar.Px(), vec_polar.Py(), vec_polar.Pz(), vec_polar.E())) # fastjet uses Cartesian as input\n",
    "        jets = jet_def(pseudojets) # perform jet clustering\n",
    "        \n",
    "        # Apply optional minimum jet pT cut\n",
    "        jet_pt = np.array([jet.pt() for jet in jets])\n",
    "        jet_indices = np.linspace(0,len(jets)-1,len(jets),dtype=np.dtype('i8'))[jet_pt >= pt_min]\n",
    "        jets = [jets[i] for i in jet_indices]\n",
    "        njets = len(jets)\n",
    "        \n",
    "        # TODO: save jet info to a TTree\n",
    "        for key in branch_buffer.keys(): branch_buffer[key].clear()\n",
    "            \n",
    "        for j in range(njets):    \n",
    "#             vec.SetCoordinates(jets[j].pt(), jets[j].eta(), jets[j].phi(), jets[j].e())\n",
    "#             print(vec.E(), vec.P(), vec.M())\n",
    "#             #print(jets[j].pt(), jets[j].e())\n",
    "            branch_buffer['AntiKt4EMTopoJetsPt'].push_back(jets[j].pt() * energy_scaling)\n",
    "            branch_buffer['AntiKt4EMTopoJetsEta'].push_back(jets[j].eta())\n",
    "            branch_buffer['AntiKt4EMTopoJetsPhi'].push_back(jets[j].phi())\n",
    "            branch_buffer['AntiKt4EMTopoJetsE'].push_back(jets[j].e() * energy_scaling)\n",
    "        \n",
    "        t.Fill()\n",
    "    t.Write(tree_name, rt.TObject.kOverwrite)\n",
    "    f.Close()\n",
    "\n",
    "tree_names['jet_em'] = tree_name\n",
    "ur_trees = {file:{tree_key:ur.open(file)[tree_name] for tree_key,tree_name in tree_names.items()} for file in data_filenames}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the kinematic distributions of our new EM jets and the old EM jets. Our hope is that they match. Note that we might expect to find some lower $p_T$ jets too, as it looks like a $p_T$ cut was applied to the original EM jets and we aren't necessarily applying one here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting various jet energies divided by pT\n",
    "jet_defs = {\n",
    "    'EM':('event', 'AntiKt4EMTopoJets'),\n",
    "    'EM2':('jet_em',   'AntiKt4EMTopoJets')\n",
    "}\n",
    "\n",
    "colors = {\n",
    "    'EM': rt.kGreen,\n",
    "    'EM2': rt.kViolet + 8\n",
    "}\n",
    "\n",
    "scale_factors = 0.001 # jet info seems to be in keV, we want to plot it all in GeV\n",
    "\n",
    "energy_hists = {key:rt.TH1F(str(uuid.uuid4()), key + ' Jets;Energy [GeV];Count', 100, 0., 100.) for key in jet_defs.keys()}\n",
    "pt_hists     = {key:rt.TH1F(str(uuid.uuid4()), key + ' Jets;p_{T} [GeV];Count', 100, 0., 100.) for key in jet_defs.keys()}\n",
    "eta_hists    = {key:rt.TH1F(str(uuid.uuid4()), key + ' Jets;#eta;Count', 100, -1., 1.) for key in jet_defs.keys()}\n",
    "m_hists      = {key:rt.TH1F(str(uuid.uuid4()), key + ' Jets;m [GeV];Count', 30, -10., 20.) for key in jet_defs.keys()}\n",
    "ep_hists     = {key:rt.TH1F(str(uuid.uuid4()), key + ' Jets;Energy / p_{T};Count', 60, 0.8, 1.4) for key in jet_defs.keys()}\n",
    "n_hists      = {key:rt.TH1I(str(uuid.uuid4()), key + ' Jets;N_{jets};Count', 20, 0, 20) for key in jet_defs.keys()}\n",
    "\n",
    "vec = rt.Math.PtEtaPhiEVector()\n",
    "for dfile in data_filenames:\n",
    "    for key, jet_def in jet_defs.items():\n",
    "        eta         =                 ur_trees[dfile][jet_def[0]].array(jet_def[1] + 'Eta')\n",
    "        n           = [len(x[np.abs(x) < global_eta_cut]) for x in eta]\n",
    "        eta         = eta.flatten()\n",
    "        jet_indices = np.linspace(0,len(eta)-1,len(eta),dtype=np.dtype('i8'))[np.abs(eta) <= global_eta_cut]\n",
    "        eta         = eta[jet_indices]\n",
    "        energy      = scale_factors * ur_trees[dfile][jet_def[0]].array(jet_def[1] + 'E').flatten()[jet_indices]\n",
    "        pt          = scale_factors * ur_trees[dfile][jet_def[0]].array(jet_def[1] + 'Pt').flatten()[jet_indices]\n",
    "        ep          = energy / pt\n",
    "        \n",
    "        for i in range(len(n)):\n",
    "            n_hists[key].Fill(n[i])\n",
    "        for i in range(len(ep)):\n",
    "            energy_hists[key].Fill(energy[i])\n",
    "            pt_hists[key].Fill(pt[i])\n",
    "            eta_hists[key].Fill(eta[i])\n",
    "            ep_hists[key].Fill(ep[i])\n",
    "            vec.SetCoordinates(pt[i],eta[i],0.,energy[i])\n",
    "            m_hists[key].Fill(vec.M())\n",
    "\n",
    "hist_lists = [energy_hists, pt_hists, eta_hists, ep_hists, m_hists, n_hists]\n",
    "for key in jet_defs.keys():\n",
    "    for hist_list in hist_lists:\n",
    "        SetColor(hist_list[key],colors[key])\n",
    "\n",
    "legend = rt.TLegend(0.7,0.7,0.9,0.9)\n",
    "legend.AddEntry(energy_hists['EM'],'EM','f')\n",
    "legend.AddEntry(energy_hists['EM2'],'EM (new)','f')\n",
    "\n",
    "rt.gStyle.SetOptStat(0)\n",
    "canvases = []\n",
    "stacks = []\n",
    "for hist_list in hist_lists:\n",
    "    c = rt.TCanvas(str(uuid.uuid4()), str(uuid.uuid4()), 800, 600)\n",
    "    c.cd()\n",
    "    c.SetLogy()\n",
    "    stack = rt.THStack(str(uuid.uuid4()),'')\n",
    "    stack.SetTitle(list(hist_list.values())[0].GetTitle())\n",
    "    for key in hist_list.keys():\n",
    "        stack.Add(hist_list[key])\n",
    "    stack.Draw('NOSTACK HIST')\n",
    "    legend.Draw()\n",
    "    cut_pave.Draw()\n",
    "    stack.GetXaxis().SetTitle(list(hist_list.values())[0].GetXaxis().GetTitle())\n",
    "    stack.GetYaxis().SetTitle(list(hist_list.values())[0].GetYaxis().GetTitle())\n",
    "    stack.SetMinimum(5.0e-1)\n",
    "    canvases.append(c)\n",
    "    stacks.append(stack)\n",
    "    canvases[-1].Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... the energy and jet multiplicity distributions are *totally* different, the $p_T$ distributions are quite similar (with our new EM jets having some lower $p_T$ members as we anticipated). But that there's any big difference in the energy, eta and multiplicity distributions suggests that something odd is happening in jet clustering on our end. This warrants further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding \"Playground\" below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an experiment, let's try rescaling the energy ratios from earlier. Is the predicted energy maybe just off by some constant factor? It seems unlikely but it doesn't hurt to try and see if rescaling the histogram will give us a (sharp?) peak near unity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(jet_energy_ratios['ML'])\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, I think the mean is thrown off by an outlier. So we can try to rescale the distribution so that the *median* or histogram *mode* is at 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawRescaledRatio(jet_energy_ratios, rescaling_factor, target_name):\n",
    "\n",
    "    energy_ratio_rescaled = jet_energy_ratios['ML'] * rescaling_factor\n",
    "    \n",
    "    colors = {\n",
    "        'EM':rt.kGreen,\n",
    "        'LC':rt.kRed,\n",
    "        'ML':rt.kBlue\n",
    "    }\n",
    "    min_ratio = 1.0e-3\n",
    "    max_ratio = 1.0e1\n",
    "    nbins = 10000\n",
    "\n",
    "    hists = {key: rt.TH1F(key + 'ratio', key + ';E_{reco}/E_{true};Count',nbins,min_ratio,max_ratio) for key in ['EM','LC','ML']}\n",
    "    for key in ['EM','LC']:\n",
    "        SetColor(hists[key],colors[key])\n",
    "        for entry in jet_energy_ratios[key]:\n",
    "            hists[key].Fill(entry)\n",
    "\n",
    "    # our rescaled ML jet histogram\n",
    "    SetColor(hists['ML'],colors['ML'])\n",
    "    for entry in energy_ratio_rescaled:\n",
    "        hists['ML'].Fill(entry)\n",
    "\n",
    "    legend = rt.TLegend(0.6,0.65,0.9,0.85)\n",
    "    legend.SetBorderSize(0)\n",
    "\n",
    "    stack = rt.THStack('stack2','Energy Ratio;E_{reco}/E_{truth};Count')\n",
    "\n",
    "    for key, hist in hists.items():\n",
    "        stack.Add(hist)\n",
    "        name = key\n",
    "        if(key == 'ML'): name = target_name\n",
    "        legend.AddEntry(hist,name,'f')\n",
    "\n",
    "    return stack, legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = np.median(jet_energy_ratios['ML'])\n",
    "rescaling_factor = 1. / median\n",
    "stack, legend = DrawRescaledRatio(jet_energy_ratios, rescaling_factor, target_name='ML (rescaled with median)')\n",
    "\n",
    "c = rt.TCanvas('c_ratio2','c_ratio2',800,600)\n",
    "rt.gStyle.SetOptStat(0)\n",
    "stack.Draw('NOSTACK HIST')\n",
    "legend.Draw()\n",
    "c.SetLogx()\n",
    "c.SetLogy()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... rescaling the `ML` distribution to have a median of $1$ isn't quite cutting it. This suggests that there are a *lot* of events in the overflow bin.\n",
    "\n",
    "Instead, let's try rescaling the distribution so that its peak is at $1$. Note that this is dependent on our choice of binning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins_tmp = 10000\n",
    "hists['ML'] = rt.TH1F(key + 'ratio', 'ML;E_{reco}/E_{true};Count',nbins_tmp,min_ratio,max_ratio)\n",
    "for entry in jet_energy_ratios['ML']:\n",
    "    hists['ML'].Fill(entry)\n",
    "binmax = hists['ML'].GetMaximumBin()\n",
    "mode = hists['ML'].GetXaxis().GetBinCenter(binmax)\n",
    "rescaling_factor = 1. / mode\n",
    "\n",
    "stack, legend = DrawRescaledRatio(jet_energy_ratios, rescaling_factor, target_name='ML (rescaled with mode)')\n",
    "c = rt.TCanvas('c_ratio3','c_ratio3',800,600)\n",
    "rt.gStyle.SetOptStat(0)\n",
    "stack.Draw('NOSTACK HIST')\n",
    "legend.Draw()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.SetLogx()\n",
    "c.SetLogy()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps unsurprisingly, there doesn't seem to be any obvious scaling that will improve things -- as we might expect, rescaling will stretch things out (and increase spread)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml4p]",
   "language": "python",
   "name": "conda-env-ml4p-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
